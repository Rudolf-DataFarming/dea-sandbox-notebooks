{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water classification with radar from Sentinel 1\n",
    "\n",
    "In order to define the coastline in a satellite image, one needs to be able to distinguish land and water. While this can be done with optical data, it is also useful to look at how it can be done with radar data. This is because radar images are largely unaffected by weather and cloud cover, so can provide a more reliable image.\n",
    "\n",
    "In this notebook, you'll explore how to distinguish land and water in Sentinel 1 images using a series of commands from the Open Data Cube, as well as some self-defined functions.\n",
    "\n",
    "As you work through the notebook you will:\n",
    "1. Pick a study area along the coast.\n",
    "1. Explore available data products and load Sentinel 1 data.\n",
    "1. Visualize the returned data.\n",
    "1. Perform pre-processing steps on the Sentinel 1 VV and VH bands.\n",
    "1. Design a classifier to distinguish land and water.\n",
    "1. Apply the classifier to the study area and interpret the results.\n",
    "1. Investigate how to identify change in the coastline.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the study area\n",
    "\n",
    "The example we've selected looks at part of the the coastline of Melville Island, which sits off the coast of the Northen Territory, Australia. The study area also contains an additional small island, which will be useful for assessing how well radar data distinguishes between land and water.\n",
    "\n",
    "Run the following two cells to set the latitude and logitude range, and then view the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = (-11.287611, -11.085876)\n",
    "longitude = (130.324262, 130.452652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.display import display_map\n",
    "display_map(latitude = latitude, longitude = longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading available data\n",
    "\n",
    "Before loading the data, we'll need to import the Open Data Cube library and load the `Datacube` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "\n",
    "dc = datacube.Datacube(app = 'sentinel-1-water-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with the Open Data Cube, it's important to check which products that are available. You can do this with the `list_products()` function provided as part of the `Datacube` class. Run the cell and identify the available Sentinel 1 products, which should contain 's1' in the name. You can scroll across the table for additional information about each available product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.list_products()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify product information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the data, you'll need to specify which product you want to load. You should have found one Sentinel 1 product in the product list. In the next cell, replace `product_name` with the name you found in the available products list. You'll need to keep the quotation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_information = dict(product = \"product_name\",\n",
    "                           output_crs = \"EPSG:4326\",\n",
    "                           resolution = (0.00013557119,0.00013557119))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "product_information = dict(product = \"s1_gamma0_geotif_scene\",\n",
    "                           output_crs = \"EPSG:4326\",\n",
    "                           resolution = (0.00013557119,0.00013557119))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify latitude and longitude information\n",
    "\n",
    "We can specify the latitude and longitude bounds of our area using the variables we defined earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_information = dict(latitude = latitude,\n",
    "                        longitude = longitude) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "You might have noticed that we defined the product and area information a little differently than we did in other notebooks. Above, we specified the information in two dictonaries, which the `dc.load()` function can access by including `**` before the name of each dictionary, as demonstrated in the next cell.\n",
    "\n",
    "*Note that the load command will return an error if you have provided an incorrect product name in the* `product_information` *dictionary. If you see such an error, check that you correctly specified the name of the Sentinel 1 data product.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dc.load(**product_information, **area_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the load was sucessful, running the next cell should return the `xarray` summary of the dataset. Make a note of dimensions and data variables, as you'll need these variables during the data preperation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize loaded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentinel 1 data has two observations, *VV* and *VH*, which correspond to the polarisation of the light sent and received by the satellite. *VV* refers to the satellite sending out vertically-polarised light and receiving vertically-polarised light back, whereas *VH* refers to the satellite sending out vertically-polarised light and receiving horizontally-polarised light back. These two bands can tell us different information about the area we're studying. \n",
    "\n",
    "Before running any plotting commands, we'll load the *matplotlib* library in the cell below, along with the *numpy* library. We'll also make use of the in-built plotting functions from *xarray*.\n",
    "\n",
    "*Note that we take the base-10 logarithm of the bands before plotting them such that we work in units of decibels (dB) rather than digital number (DN)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize VH bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all VH observations for the year \n",
    "\n",
    "converted_vh = np.log10(dataset.vh)  # Scale to plot data in decibels\n",
    "\n",
    "converted_vh.plot(cmap=\"Blues\", col=\"time\", col_wrap=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average of all VH observations\n",
    "\n",
    "mean_converted_vh = converted_vh.mean(dim = \"time\")\n",
    "\n",
    "fig = plt.figure(figsize=(7,9))\n",
    "mean_converted_vh.plot(cmap = \"Blues\")\n",
    "plt.title(\"Average VH\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What key differences do you notice between each individual observation and the mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize VV bands  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided two empty cells for you to perform the same analysis as above, but now for the *VV* band. Try and type the code out -- it will help you get better at using the Open Data Cube library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all VV observations for the year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "converted_vv = np.log10(dataset.vv)  # Scale to plot data in decibels\n",
    "\n",
    "converted_vv.plot(cmap=\"Blues\", col=\"time\", col_wrap=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average of all VV observations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "mean_converted_vv = converted_vv.mean(dim = \"time\")\n",
    "\n",
    "fig = plt.figure(figsize=(7,9))\n",
    "mean_converted_vv.plot(cmap = \"Blues\")\n",
    "plt.title(\"Average VV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What key differences do you notice between each individual observation and the mean? What about differences between the average *VH* and *VV* bands?\n",
    "\n",
    "Take a look back at the map image to remind yourself of the shape of the land and water of our study area. In both bands, what distinguishes the land and the water?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data through filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speckle Filtering using Lee Filter\n",
    "\n",
    "You may have noticed that the water in the individual *VV* and *VH* images isn't a consistent colour. The distortion you're seeing is a type of noise known as speckle, which gives the images a grainy appearence. If we want to be able to easily decide whether any particular pixel is water or land, we need to reduce the chance of misinterpreting a water pixel as a land pixel due to the noise.\n",
    "\n",
    "Speckle can be removed through filtering. If interested, you can find a technical introduction to speckle filtering [here](https://earth.esa.int/documents/653194/656796/Speckle_Filtering.pdf). For now, it is enough to know that we can filter the data using the python function defined in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "\n",
    "def lee_filter(da, size):\n",
    "    img = da.values\n",
    "    img_mean = uniform_filter(img, (size, size))\n",
    "    img_sqr_mean = uniform_filter(img**2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the filter, we can run it on the *VV* and *VH* data. You might have noticed that the function takes a `size` argument. This will change how blurred the image becomes after smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set any null values to 0 before applying the filter to prevent issues\n",
    "dataset_zero_filled = dataset.where(~dataset.isnull(), 0)\n",
    "\n",
    "# Create a new entry in dataset corresponding to filtered VV and VH data\n",
    "dataset[\"filtered_vv\"] = dataset_zero_filled.vv.groupby('time').apply(lee_filter, size=7)\n",
    "dataset[\"filtered_vh\"] = dataset_zero_filled.vh.groupby('time').apply(lee_filter, size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Filtered VH bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all filtered VH observations for the year \n",
    "\n",
    "converted_filtered_vh = np.log10(dataset.filtered_vh)  # Scale to plot data in decibels\n",
    "\n",
    "converted_filtered_vh.plot(cmap=\"Blues\", col=\"time\", col_wrap=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average of all filtered VH observations\n",
    "\n",
    "mean_converted_filtered_vh = converted_filtered_vh.mean(dim = \"time\")\n",
    "\n",
    "fig = plt.figure(figsize=(7,9))\n",
    "mean_converted_filtered_vh.plot(cmap = \"Blues\")\n",
    "plt.title(\"Average filtered VH\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Filtered VV bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all filtered VV observations for the year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "converted_filtered_vv = np.log10(dataset.filtered_vv)  # Scale to plot data in decibels\n",
    "\n",
    "converted_filtered_vv.plot(cmap=\"Blues\", col=\"time\", col_wrap=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average of all filtered VH observations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "mean_converted_filtered_vv = converted_filtered_vv.mean(dim = \"time\")\n",
    "\n",
    "fig = plt.figure(figsize=(7,9))\n",
    "mean_converted_filtered_vv.plot(cmap = \"Blues\")\n",
    "plt.title(\"Average filtered VV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've finished filtering the data, compare the plots before and after and you should be able to notice the impact of the filtering. If you're having trouble spotting it, it's more noticable in the VH band. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing VV and VH histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to observe the impact of filtering is to view histograms of the pixel values before and after filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,3))\n",
    "_ = np.log10(dataset.filtered_vv).plot.hist(bins = 1000, label = \"VV filtered\")\n",
    "_ = np.log10(dataset.vv).plot.hist(bins = 1000, label = \"VV\", alpha = .5)\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of filtered VV bands to original\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,3))\n",
    "_ = np.log10(dataset.filtered_vh).plot.hist(bins = 1000, label = \"VH filtered\")\n",
    "_ = np.log10(dataset.vh).plot.hist(bins = 1000, label = \"VH\", alpha = .5)\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of filtered VH bands to original\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing a threshold based water classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2d visualization of imagery alone, suggests a stark contrast in `land` and `water` values.    \n",
    "The visualization of the fitlered S1 data highlights a clear bimodal distribution on the `filtered VH` domain.   \n",
    "\n",
    "In this section, a classifier is built based on a static threshold on `filtered_vh` values.  \n",
    "\n",
    "$$ threshold = -2.0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier separates data into two classes, data above, and data below the threshold. An assumption is made that values of both segments correspond to the same `water` and `not water` distinctions we make visually.  \n",
    "\n",
    "\n",
    "<br>  \n",
    "\n",
    "$$  water(Dataset) = \\left\\{\n",
    "     \\begin{array}{lr}\n",
    "       True & :   Dataset_{VH} \\le threshold\\\\\n",
    "       False & :   Dataset_{VH} > threshold\n",
    "     \\end{array}\n",
    "   \\right.\\\\ $$  \n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,3))\n",
    "plt.axvline(x=-2, label='Threshold at {}'.format(threshold), color = \"red\")\n",
    "_ = np.log10(dataset.filtered_vh).plot.hist(bins = 1000, label = \"VH filtered\")\n",
    "_ = np.log10(dataset.vh).plot.hist(bins = 1000, label = \"VH\", alpha = .5)\n",
    "plt.legend()\n",
    "plt.title(\"Histogram Comparison of filtered VH bands to original\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,3))\n",
    "_ = np.log10(dataset.filtered_vh).plot.hist(bins = 1000, label = \"VH filtered\")\n",
    "ax.axvspan(xmin=-2,xmax = -.5, alpha=0.25, color='red', label = \"Not Water\")\n",
    "ax.axvspan(xmin=-3.5,xmax = -2, alpha=0.25, color='green', label = \"Water\")\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of filtered VH bands to original\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr \n",
    "\n",
    "def s1_water_classifier(ds:xr.Dataset, threshold = -2) -> xr.Dataset:\n",
    "    assert \"vh\" in ds.data_vars, \"This classifier is expecting a variable named `vh` expressed in DN, not DB values\"\n",
    "    filtered = ds.vh.groupby('time').apply(lee_filter, size=7)\n",
    "    water_data_array = np.log10(filtered) < threshold\n",
    "    return water_data_array.to_dataset(name = \"s1_wofs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"s1_wofs\"] = s1_water_classifier(dataset).s1_wofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water Classification Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "dataset.s1_wofs.mean(dim = \"time\").plot(cmap = \"jet_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Interpretation and Ideas: \n",
    "\n",
    "- There exists fairly consistent classifications inland and off the coasts.  \n",
    "- The coastline in not consitently water.\n",
    "- Check Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water Classification Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "dataset.s1_wofs.std(dim = \"time\").plot(cmap = \"jet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Interpretation and Ideas: \n",
    "\n",
    "- variance can capture long term trends like coastal erosion or degredation, but may also capture noise.  \n",
    "  take, for example an alternating sequence of classifications $ts_1 = [0,1,0,1,...,0,1, 0, 1]$ and the sequence $ts_2 = [0,0,0,0,...,1,1,1,1]$    \n",
    "  It's safe to assume that $var(ts_1) == var(ts_2)$ despite the fact that one might be frequent alternating changes in state of water, while the later might be lasting transition. \n",
    "  \n",
    "- The coastline is not always consitently water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Coastal Change "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Differencing Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 0\n",
    "t2 = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change = dataset.s1_wofs.isel(time = t1) - dataset.s1_wofs.isel(time = t2)\n",
    "change = change.where(change != 0) \n",
    "dataset[\"change\"] = change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "dataset.filtered_vh.mean(dim = \"time\").plot(cmap = \"Blues\")\n",
    "dataset.change.plot(cmap = \"jet\", levels = 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtk(ts:np.array, k = 1):\n",
    "    a = np.append(np.array(ts).copy(),\n",
    "                  np.zeros(k))\n",
    "    \n",
    "    b = np.append(np.zeros(k),\n",
    "                  np.array(ts).copy())\n",
    "    \n",
    "    auto = (a * b)[k:-k]\n",
    "    return np.mean(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_correlation_ds = xr.DataArray(auto_correlation, dims = dict((k, dataset[k].values) for k in ('latitude', 'longitude')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_correlation = np.apply_along_axis(rtk,0,dataset.s1_wofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_correlation_ds = xr.DataArray(auto_correlation, dims = dict((k, dataset[k].values) for k in ('latitude', 'longitude')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = dataset.s1_wofs.mean(dim = \"time\")\n",
    "varying_pixels = np.logical_and(freq != 0, freq != 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,3))\n",
    "_ = auto_correlation_ds.where(varying_pixels).plot.hist(bins = 256)\n",
    "plt.title(\"Histogram of autocorrelation\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "dataset.filtered_vh.mean(dim = \"time\").plot(cmap = \"Blues\")\n",
    "dataset.change.where(auto_correlation_ds > 0.8).plot(cmap = \"jet\", levels = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
