{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water classification with radar from Sentinel 1\n",
    "\n",
    "In order to define the coastline in a satellite image, one needs to be able to distinguish land and water. While this can be done with optical data, it is also useful to look at how it can be done with radar data. This is because radar images are largely unaffected by weather and cloud cover, so can provide a more reliable image.\n",
    "\n",
    "In this notebook, you'll explore how to distinguish land and water in Sentinel 1 images using a series of commands from the Open Data Cube, as well as some self-defined functions.\n",
    "\n",
    "As you work through the notebook you will:\n",
    "1. Pick a study area along the coast.\n",
    "1. Explore available data products and load Sentinel 1 data.\n",
    "1. Visualize the returned data.\n",
    "1. Perform pre-processing steps on the Sentinel 1 VV and VH bands.\n",
    "1. Design a classifier to distinguish land and water.\n",
    "1. Apply the classifier to the study area and interpret the results.\n",
    "1. Investigate how to identify change in the coastline.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the study area\n",
    "\n",
    "The example we've selected looks at part of the the coastline of Melville Island, which sits off the coast of the Northen Territory, Australia. The study area also contains an additional small island, which will be useful for assessing how well radar data distinguishes between land and water.\n",
    "\n",
    "Run the following two cells to set the latitude and logitude range, and then view the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = (-11.287611, -11.085876)\n",
    "longitude = (130.324262, 130.452652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.display import display_map\n",
    "display_map(latitude = latitude, longitude = longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading available data\n",
    "\n",
    "Before loading the data, we'll need to import the Open Data Cube library and load the `Datacube` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "\n",
    "dc = datacube.Datacube(app = 'sentinel-1-water-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with the Open Data Cube, it's important to check which products that are available. You can do this with the `list_products()` function provided as part of the `Datacube` class. Run the cell and identify the available Sentinel 1 products, which should contain 's1' in the name. You can scroll across the table for additional information about each available product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.list_products()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify product information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the data, you'll need to specify which product you want to load. You should have found one Sentinel 1 product in the product list. In the next cell, replace `product_name` with the name you found in the available products list. You'll need to keep the quotation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_information = dict(product = \"product_name\",\n",
    "                           output_crs = \"EPSG:4326\",\n",
    "                           resolution = (0.00013557119,0.00013557119))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "product_information = dict(product = \"s1_gamma0_geotif_scene\",\n",
    "                           output_crs = \"EPSG:4326\",\n",
    "                           resolution = (0.00013557119,0.00013557119))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify latitude and longitude information\n",
    "\n",
    "We can specify the latitude and longitude bounds of our area using the variables we defined earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_information = dict(latitude = latitude,\n",
    "                        longitude = longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "You might have noticed that we defined the product and area information a little differently than we did in other notebooks. Above, we specified the information in two dictonaries, which the `dc.load()` function can access by including `**` before the name of each dictionary, as demonstrated in the next cell.\n",
    "\n",
    "*Note that the load command will return an error if you have provided an incorrect product name in the* `product_information` *dictionary. If you see such an error, check that you correctly specified the name of the Sentinel 1 data product.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dc.load(**product_information, **area_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the load was sucessful, running the next cell should return the `xarray` summary of the dataset. Make a note of dimensions and data variables, as you'll need these variables during the data preperation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize loaded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentinel 1 data has two observations, *VV* and *VH*, which correspond to the polarisation of the light sent and received by the satellite. *VV* refers to the satellite sending out vertically-polarised light and receiving vertically-polarised light back, whereas *VH* refers to the satellite sending out vertically-polarised light and receiving horizontally-polarised light back. These two bands can tell us different information about the area we're studying. \n",
    "\n",
    "Before running any plotting commands, we'll load the *matplotlib* library in the cell below, along with the *numpy* library. We'll also make use of the in-built plotting functions from *xarray*.\n",
    "\n",
    "*Note that we take the base-10 logarithm of the bands before plotting them such that we work in units of decibels (dB) rather than digital number (DN)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize VH bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all VH observations for the year \n",
    "\n",
    "converted_vh = np.log10(dataset.vh)  # Scale to plot data in decibels\n",
    "\n",
    "converted_vh.plot(cmap=\"Blues\", col=\"time\", col_wrap=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average of all VH observations\n",
    "\n",
    "mean_converted_vh = converted_vh.mean(dim = \"time\")\n",
    "\n",
    "fig = plt.figure(figsize=(7,9))\n",
    "mean_converted_vh.plot(cmap = \"Blues\")\n",
    "plt.title(\"Average VH\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What key differences do you notice between each individual observation and the mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize VV bands  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided two empty cells for you to perform the same analysis as above, but now for the *VV* band. Try and type the code out -- it will help you get better at using the Open Data Cube library!\n",
    "\n",
    "*Hint: You'll want to perform the same steps, but change the data variable. We've already used the `vh` variable, so you can go back and check thje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all VV observations for the year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "converted_vv = np.log10(dataset.vv)  # Scale to plot data in decibels\n",
    "\n",
    "converted_vv.plot(cmap=\"Blues\", col=\"time\", col_wrap=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average of all VV observations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "mean_converted_vv = converted_vv.mean(dim = \"time\")\n",
    "\n",
    "fig = plt.figure(figsize=(7,9))\n",
    "mean_converted_vv.plot(cmap = \"Blues\")\n",
    "plt.title(\"Average VV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What key differences do you notice between each individual observation and the mean? What about differences between the average *VH* and *VV* bands?\n",
    "\n",
    "Take a look back at the map image to remind yourself of the shape of the land and water of our study area. In both bands, what distinguishes the land and the water?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data through filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speckle Filtering using Lee Filter\n",
    "\n",
    "You may have noticed that the water in the individual *VV* and *VH* images isn't a consistent colour. The distortion you're seeing is a type of noise known as speckle, which gives the images a grainy appearence. If we want to be able to easily decide whether any particular pixel is water or land, we need to reduce the chance of misinterpreting a water pixel as a land pixel due to the noise.\n",
    "\n",
    "Speckle can be removed through filtering. If interested, you can find a technical introduction to speckle filtering [here](https://earth.esa.int/documents/653194/656796/Speckle_Filtering.pdf). For now, it is enough to know that we can filter the data using the python function defined in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "\n",
    "def lee_filter(da, size):\n",
    "    img = da.values\n",
    "    img_mean = uniform_filter(img, (size, size))\n",
    "    img_sqr_mean = uniform_filter(img**2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the filter, we can run it on the *VV* and *VH* data. You might have noticed that the function takes a `size` argument. This will change how blurred the image becomes after smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set any null values to 0 before applying the filter to prevent issues\n",
    "dataset_zero_filled = dataset.where(~dataset.isnull(), 0)\n",
    "\n",
    "# Create a new entry in dataset corresponding to filtered VV and VH data\n",
    "dataset[\"filtered_vv\"] = dataset_zero_filled.vv.groupby('time').apply(lee_filter, size=7)\n",
    "dataset[\"filtered_vh\"] = dataset_zero_filled.vh.groupby('time').apply(lee_filter, size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Filtered VH bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all filtered VH observations for the year \n",
    "\n",
    "converted_filtered_vh = np.log10(dataset.filtered_vh)  # Scale to plot data in decibels\n",
    "\n",
    "converted_filtered_vh.plot(cmap=\"Blues\", col=\"time\", col_wrap=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average of all filtered VH observations\n",
    "\n",
    "mean_converted_filtered_vh = converted_filtered_vh.mean(dim = \"time\")\n",
    "\n",
    "fig = plt.figure(figsize=(7,9))\n",
    "mean_converted_filtered_vh.plot(cmap = \"Blues\")\n",
    "plt.title(\"Average filtered VH\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Filtered VV bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all filtered VV observations for the year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "converted_filtered_vv = np.log10(dataset.filtered_vv)  # Scale to plot data in decibels\n",
    "\n",
    "converted_filtered_vv.plot(cmap=\"Blues\", col=\"time\", col_wrap=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average of all filtered VH observations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "mean_converted_filtered_vv = converted_filtered_vv.mean(dim = \"time\")\n",
    "\n",
    "fig = plt.figure(figsize=(7,9))\n",
    "mean_converted_filtered_vv.plot(cmap = \"Blues\")\n",
    "plt.title(\"Average filtered VV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've finished filtering the data, compare the plots before and after and you should be able to notice the impact of the filtering. If you're having trouble spotting it, it's more noticable in the VH band. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing VV and VH histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to observe the impact of filtering is to view histograms of the pixel values before and after filtering. Try running the next two cells to view the histograms for *VV* and *VH*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,3))\n",
    "_ = np.log10(dataset.filtered_vv).plot.hist(bins = 1000, label = \"VV filtered\")\n",
    "_ = np.log10(dataset.vv).plot.hist(bins = 1000, label = \"VV\", alpha = .5)\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of filtered VV bands to original\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,3))\n",
    "_ = np.log10(dataset.filtered_vh).plot.hist(bins = 1000, label = \"VH filtered\")\n",
    "_ = np.log10(dataset.vh).plot.hist(bins = 1000, label = \"VH\", alpha = .5)\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of filtered VH bands to original\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that both the original and filtered bands show two peaks in the histogram, which we can classify as a bimodal distribution. Looking back at the band images, it's clear that the water pixels generally have lower *VH* and *VV* values than the land pixels, indicated by the positions of the two peaks. Importantly, the act of filtering has made it clear that there are two distinct pixel value distributions, which is especially obvious in the *VH* plot. This allows us to confidently say that pixel values below a certain threshold are water, and pixel values above it are land. This will form the basis for our classifier in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing a threshold-based water classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the distinction between the `land` and `water` pixel value distributions is strongest in the *VH* band, we'll base our classifier on this distribution. To separate them, we can choose a threshold: pixels with values below the threshold are water, and pixels with values above the threshold are not water (land).\n",
    "\n",
    "There are a number of ways to determine the threshold; one is to estimate it by looking at the *VH* histogram. From this, we might guess that $\\text{threshold} = -2.0$ is a reasonable value. Run the cell below to set the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier separates data into two classes, data above, and data below the threshold. In doing this, we assume that values of both segments correspond to the same `water` and `not water` distinctions we make visually. This can be represented with a step function:\n",
    "\n",
    "$$  \\text{water}(VH) = \\left\\{\n",
    "     \\begin{array}{lr}\n",
    "       \\text{True} & :   VH < \\text{threshold}\\\\\n",
    "       \\text{False} & :  VH \\geq \\text{threshold}\n",
    "     \\end{array}\n",
    "   \\right.\\\\ $$  \n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize threshold\n",
    "\n",
    "To check if our chosen threshold reasonably divides the two distributions, we can add the threshold to the histogram plots we made earlier. Run the next two cells to view two different visualizations of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,3))\n",
    "plt.axvline(x=-2, label='Threshold at {}'.format(threshold), color = \"red\")\n",
    "_ = np.log10(dataset.filtered_vh).plot.hist(bins = 1000, label = \"VH filtered\")\n",
    "_ = np.log10(dataset.vh).plot.hist(bins = 1000, label = \"VH\", alpha = .5)\n",
    "plt.legend()\n",
    "plt.title(\"Histogram Comparison of filtered VH bands to original\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,3))\n",
    "_ = np.log10(dataset.filtered_vh).plot.hist(bins = 1000, label = \"VH filtered\")\n",
    "ax.axvspan(xmin=-2,xmax = -.5, alpha=0.25, color='red', label = \"Not Water\")\n",
    "ax.axvspan(xmin=-3.7,xmax = -2, alpha=0.25, color='green', label = \"Water\")\n",
    "plt.legend()\n",
    "plt.title(\"Effect of the classifier\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're curious about how changing the threshold impacts the classifier, try changing the threshold value and running the previous two cells again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and apply the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the threshold, we can write a function to only return the pixels that are classified as water. The basic steps that the function will perform are:\n",
    "1. Check that the data set has a VH band to classify.\n",
    "1. Filter the data to distinguish the `water` and `not water` distributions.\n",
    "1. Convert the VH band measurements from digital number (DN) to decibels (dB) by taking the logarithm.\n",
    "1. Find all pixels that have filtered dB values lower than the threshold; these are the `water` pixels.\n",
    "1. Return a data set containing the `water` pixels\n",
    "\n",
    "These steps correspond to the actions taken in the function below. See if you can determine which parts of the function map to each step before you continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr \n",
    "\n",
    "def s1_water_classifier(ds:xr.Dataset, threshold = -2) -> xr.Dataset:\n",
    "    assert \"vh\" in ds.data_vars, \"This classifier is expecting a variable named `vh` expressed in DN, not DB values\"\n",
    "    filtered = ds.vh.groupby('time').apply(lee_filter, size=7)\n",
    "    water_data_array = np.log10(filtered) < threshold\n",
    "    return water_data_array.to_dataset(name = \"s1_water\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the classifier function, we can apply it to the data. After you run the classifier, you'll be able to view the classified data product by running `print(dataset.s1_water)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"s1_water\"] = s1_water_classifier(dataset).s1_water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation with mean\n",
    "\n",
    "We can now view the image with our classification. The classifier returns either `True` or `False` for each pixel. To detect the shoreline, we want to check which pixels are always water and which are always land. Conveniently, Python encodes `True = 1` and `False = 0`. If we plot the average classified pixel value, pixels that are always water will have an average value of `1` and pixels that are always land will have an average of `0`. Pixels that are sometimes water and sometimes land will have an average between these values.\n",
    "\n",
    "The following cell plots the average classified pixel value over time. How might you classify the shoreline from the average classification value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean of each classified pixel value\n",
    "\n",
    "plt.figure(figsize = (15,12))\n",
    "dataset.s1_water.mean(dim = \"time\").plot(cmap = \"RdBu\")\n",
    "plt.title(\"Average classified pixel value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the mean classification \n",
    "\n",
    "From the image above, you should be able to see that the shoreline takes on a mix of values between `0` and `1`. You can also see that our threshold has done a good job of separating the water pixels (in blue) and land pixels (in red). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation with standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we've identified the shoreline as the pixels that are calssified sometimes as land and sometimes as water, we can also see if the standard deviation of each pixel in time is a reasonable way to determine if a pixel is shoreline or not. Similar to how we calculated and plotted the mean above, you can calculate and plot the standard deviation by using the `std` function in place of the `mean` function. Try writing the code in the next cell.\n",
    "\n",
    "*Hint: the only things you'll need to change from the code above are the function you use and the title of the plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the standard deviation of each classified pixel value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer -- remove later. Keep for running purposes.\n",
    "\n",
    "plt.figure(figsize = (15,12))\n",
    "dataset.s1_water.std(dim = \"time\").plot(cmap = \"RdBu\")\n",
    "plt.title(\"Standard deviation of classified pixel value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the standard deviation of the classification\n",
    "\n",
    "From the image above, you should be able to see that the land and water pixels almost always have a standard deviation of `0`, meaning they didn't change over the time we sampled. With further invesitgation, you could potentially turn this statistic into a new classifier to extract shoreline pixels. If you're after a challenge, have a think about how you might approach this.\n",
    "\n",
    "An important thing to recognise is that the standard deviation might not be able to detect the difference between noise and ongoing change, since a pixel that frequently alternates between land and water (noise) could have the same standard deviation as a pixel that is land for some time, then becomes water for the remaining time (ongoing change). Consider how you might distinguish between these two different cases with the data and tools you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting coastal change\n",
    "\n",
    "The standard deviation we calculated before gives us an idea of how much the pixel has changed over the entire period of time that we looked at. It might also be interesting to look at which pixels have changed between any two particular times in our sample.\n",
    "\n",
    "In the next cell, we choose the images to compare. Printing the dataset should show you that there are 27 time-steps, so the first has an index value of `0`, and the last has an index value of `26`. You can change these to be any numbers in between, as long as the start is earlier than the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_index = 0\n",
    "end_time_index = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define the change as the difference in the classified pixel value at each point. Land becoming water will have a value of `-1` and water becoming land will have a value of `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change = dataset.s1_water.isel(time = start_time_index) - dataset.s1_water.isel(time = end_time_index)\n",
    "change = change.where(change != 0)  # set all '0' entries to NaN, which prevents them from displaying in the plot.\n",
    "dataset[\"change\"] = change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've added change to the data set, you should be able to plot it below to look at which pixels changed. You can also plot the original mean *VH* composite to see how well the change matches our understanding of the shoreline location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "dataset.filtered_vh.mean(dim = \"time\").plot(cmap = \"Blues\")\n",
    "dataset.change.plot(cmap = \"RdBu\", levels = 2)\n",
    "plt.title('Change in pixel value between time={} and time={}'.format(start_time_index, end_time_index))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing conclusions\n",
    "Here are some questions to think about:\n",
    "\n",
    "* What are the benefits and drawbacks of the possible classification options we explored?\n",
    "* How could you extend the analysis to extract a shape for the coastline?\n",
    "* How reliable is our classifier?\n",
    "* Is there anything you can think of that would improve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "When you are done, you can return to the start of the notebook and change the latitude and longitude if you're interested in rerunning the analysis for a new location. If you're going to change the location, you'll need to make sure Sentinel 1 data is available for the new location, which you can check at the [DEA Dashboard](https://dashboard.dea-sandbox.test.frontiersi.io/s1_gamma0_geotif_scene)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO REVIEW -- DO WE NEED THIS? Auto Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtk(ts:np.array, k = 1):\n",
    "    a = np.append(np.array(ts).copy(),\n",
    "                  np.zeros(k))\n",
    "    \n",
    "    b = np.append(np.zeros(k),\n",
    "                  np.array(ts).copy())\n",
    "    \n",
    "    auto = (a * b)[k:-k]\n",
    "    return np.mean(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_correlation_ds = xr.DataArray(auto_correlation, dims = dict((k, dataset[k].values) for k in ('latitude', 'longitude')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_correlation = np.apply_along_axis(rtk,0,dataset.s1_wofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_correlation_ds = xr.DataArray(auto_correlation, dims = dict((k, dataset[k].values) for k in ('latitude', 'longitude')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = dataset.s1_wofs.mean(dim = \"time\")\n",
    "varying_pixels = np.logical_and(freq != 0, freq != 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,3))\n",
    "_ = auto_correlation_ds.where(varying_pixels).plot.hist(bins = 256)\n",
    "plt.title(\"Histogram of autocorrelation\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "dataset.filtered_vh.mean(dim = \"time\").plot(cmap = \"Blues\")\n",
    "dataset.change.where(auto_correlation_ds > 0.8).plot(cmap = \"jet\", levels = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
