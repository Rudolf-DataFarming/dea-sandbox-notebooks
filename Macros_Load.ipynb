{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.utils import (\n",
    "    lat_lon_to_epsg)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datacube import Datacube\n",
    "import xarray\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout,HBox, VBox,Accordion,ToggleButtons,SelectionRangeSlider,Label\n",
    "import json\n",
    "import os\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "from traitlets import link\n",
    "import datetime\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import uuid\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "###need to add lat long and address search\n",
    "\n",
    "if 'center' not in locals():\n",
    "    center =[-34.42989,116.63979]\n",
    "    \n",
    "zoom = 13\n",
    "\n",
    "product_summary = widgets.Output(layout={'border': '1px solid black'})\n",
    "#dimensions = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "\n",
    "def generate_available_datasets_table():\n",
    "    products_from_cube = dc.list_products()\n",
    "    product_list = list(dc.list_products()['name'].values)\n",
    "    product_description = list(dc.list_products()['description'].values)\n",
    "    \n",
    "    build_table = []\n",
    "    \n",
    "    config = load_config('./configIndex.txt')\n",
    "    \n",
    "    for num, product in enumerate(product_list):\n",
    "        ds = dc.find_datasets(product=product,\n",
    "                 latitude=tuple(config['lat']),\n",
    "                 longitude=tuple(config['lon']),\n",
    "                 time=tuple(sorted(config['time']))\n",
    "                 )\n",
    "        captured_dates = []\n",
    "        for dataset in ds:\n",
    "            captured_dates.append(dataset.time.begin.date())\n",
    "        if len(captured_dates)>0:\n",
    "            number_epochs = len(set(captured_dates))\n",
    "            number_tiles =  len(captured_dates)\n",
    "\n",
    "            captured_dates_sorted = sorted(captured_dates)\n",
    "\n",
    "            start_date = captured_dates_sorted[0]\n",
    "            end_date = captured_dates_sorted[len(captured_dates_sorted)-1]\n",
    "\n",
    "\n",
    "            build_table.append([product,\n",
    "                               product_description[num],\n",
    "                               number_tiles,\n",
    "                               number_epochs,\n",
    "                               start_date,\n",
    "                               end_date\n",
    "                               ])\n",
    "    build_table = pd.DataFrame(build_table,columns = ['Product Name', \n",
    "                                                    'Product Description',\n",
    "                                                    'Number of Tiles',\n",
    "                                                    'Number of Epochs',\n",
    "                                                    'Start Date',\n",
    "                                                    'End Date'])\n",
    "    product_summary.clear_output()\n",
    "    with product_summary:\n",
    "        display(build_table)\n",
    "\n",
    "\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "    \n",
    "def update_config(filename,variable,value):\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        data[variable] = value\n",
    "        \n",
    "    os.remove(filename)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "m = Map(center=center, zoom=zoom)\n",
    "m2 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery,layout=m.layout)\n",
    "\n",
    "\n",
    "draw_control = DrawControl(rectangle={'shapeOptions': {'color': '#0000FF'}})\n",
    "draw_control2 = DrawControl(rectangle={'shapeOptions': {'color': '#0000FF'}})\n",
    "\n",
    "def handle_draw(self, action, geo_json):\n",
    "    if action == 'created':\n",
    "        m2.add_layer(GeoJSON(data=draw_control.last_draw))\n",
    "        draw_control2.last_draw =draw_control.last_draw\n",
    "        \n",
    "        lon_max = max([draw_control.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "        lon_min = min([draw_control.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "\n",
    "        lat_max = max([draw_control.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        lat_min = min([draw_control.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        EPSG = lat_lon_to_epsg(lat_max,lon_min)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #lat = {'lat' : (lat_max,lat_min),\n",
    "        #          'lon' : (lon_max,lon_min)}\n",
    "        update_config('./configIndex.txt',\n",
    "                 'output_crs',\n",
    "                 'epsg:' + EPSG)\n",
    "            \n",
    "        update_config('./configIndex.txt',\n",
    "                 'lat',\n",
    "                 (lat_max,lat_min))\n",
    "\n",
    "        update_config('./configIndex.txt',\n",
    "                 'lon',\n",
    "                 (lon_max,lon_min))\n",
    "        update_config('./configIndex.txt',\n",
    "              'geoJSON',\n",
    "              draw_control.last_draw\n",
    "             )\n",
    "        update_config('./configIndex.txt',\n",
    "              'load_id',\n",
    "              str(uuid.uuid4())\n",
    "             )\n",
    "\n",
    "\n",
    "    if action == 'deleted':\n",
    "        while len(m2.layers)>1:\n",
    "            m2.remove_layer(m2.layers[1])\n",
    "\n",
    "def handle_draw2(self, action, geo_json):\n",
    "    \n",
    "    if action == 'created':\n",
    "        m.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "        draw_control.last_draw =draw_control2.last_draw\n",
    "        \n",
    "        lon_max = max([draw_control2.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "        lon_min = min([draw_control2.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "\n",
    "        lat_max = max([draw_control2.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        lat_min = min([draw_control2.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        EPSG = lat_lon_to_epsg(lat_max,lon_min)\n",
    "        \n",
    "        update_config('./configIndex.txt',\n",
    "                 'output_crs',\n",
    "                 'epsg:' + EPSG)\n",
    "            \n",
    "        update_config('./configIndex.txt',\n",
    "                 'lat',\n",
    "                 (lat_max,lat_min))\n",
    "\n",
    "        update_config('./configIndex.txt',\n",
    "                 'lon',\n",
    "                 (lon_max,lon_min))\n",
    "        \n",
    "        update_config('./configIndex.txt',\n",
    "                      'geoJSON',\n",
    "                      draw_control2.last_draw\n",
    "                     )\n",
    "        update_config('./configIndex.txt',\n",
    "              'load_id',\n",
    "              str(uuid.uuid4())\n",
    "             )\n",
    "\n",
    "\n",
    "    if action == 'deleted':\n",
    "        while len(m.layers)>1:\n",
    "            m.remove_layer(m.layers[1])\n",
    "            \n",
    "#add handlers to draw controls  \n",
    "draw_control.on_draw(handle_draw)\n",
    "draw_control2.on_draw(handle_draw2)\n",
    "\n",
    "#add draw controls to maps\n",
    "m.add_control(draw_control)\n",
    "m2.add_control(draw_control2)\n",
    "\n",
    "#We can use link to synchronize traitlets of the two maps:\n",
    "\n",
    "map_center_link = link((m, 'center'), (m2, 'center'))\n",
    "map_zoom_link = link((m, 'zoom'), (m2, 'zoom'))\n",
    "\n",
    "dates = [datetime.date(1986,1,1) + datetime.timedelta(days =i) for i in range(1,12550)]\n",
    "date_range = SelectionRangeSlider(options=dates,\n",
    "                                          description = 'Date Range',\n",
    "                                          disabled=False,\n",
    "                                          layout = Layout(width='100%',height = '100px'))\n",
    "\n",
    "def date_func(b):\n",
    "    start_date,end_date = date_range.value\n",
    "    update_config('./configIndex.txt',\n",
    "                  'time',\n",
    "                  (start_date.strftime(\"%Y-%m-%d\"),\n",
    "                   end_date.strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "    generate_available_datasets_table()\n",
    "\n",
    "button = widgets.Button(description=\"Query Cube\",\n",
    "                       button_Style = 'success',\n",
    "                       layout=Layout(width='100%', height = '40px'))\n",
    "\n",
    "button.on_click(date_func)\n",
    "    \n",
    "case_study_select = VBox([m,m2,product_summary, date_range, button])\n",
    "    \n",
    "#date_range.observe(date_func, names = 'value')\n",
    "\n",
    "exe_load = True\n",
    "\n",
    "accordion = Accordion(children=[case_study_select])\n",
    "accordion.set_title(0, 'Select Case Study')\n",
    "accordion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro select_case_study_area 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store select_case_study_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Sentinel App\n",
    "%pylab notebook\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "if 'loaded' not in locals():\n",
    "    loaded = {}\n",
    "    loaded['sent'] = None\n",
    "    loaded['landsat8_geomed'] = None\n",
    "    loaded['landsat7_geomed'] = None\n",
    "    loaded['landsat5_geomed'] = None\n",
    "    loaded['landsat8_frac'] = None\n",
    "    loaded['landsat7_frac'] = None\n",
    "    loaded['landsat5how_frac'] = None\n",
    "\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "    \n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_sentinel(measurements = None, cloud_mask = False):\n",
    "    try: \n",
    "        data = load_config(case_study)\n",
    "        ds_s2a = dc.load(product='s2a_nrt_granule', \n",
    "                     measurements = ('nbar_red','nbar_green','nbar_blue','nbar_nir_1','nbar_swir_2','nbar_swir_3','fmask'),\n",
    "                     group_by='solar_day',\n",
    "                     y=tuple(data['lat']),\n",
    "                     x=tuple(data['lon']),\n",
    "                     time=tuple(data['time']),\n",
    "                     resolution = (-10,10),\n",
    "                     output_crs='epsg:3577')\n",
    "\n",
    "\n",
    "        crs = ds_s2a.crs\n",
    "        affine = ds_s2a.affine\n",
    "\n",
    "\n",
    "        clear_pixels = [0,2,3]\n",
    "        clear_pixels_mask = xarray.DataArray(np.in1d(ds_s2a.fmask, clear_pixels).reshape(ds_s2a.fmask.shape), \n",
    "                                             dims=ds_s2a.fmask.dims, \n",
    "                                             coords=ds_s2a.fmask.coords)\n",
    "\n",
    "        ds_s2a = ds_s2a.where(clear_pixels_mask)\n",
    "\n",
    "        ds_s2a.attrs['crs'] = crs\n",
    "        ds_s2a.attrs['affine'] = affine\n",
    "\n",
    "        ds_s2b = dc.load(product='s2b_nrt_granule', \n",
    "                     measurements = ('nbar_red','nbar_green','nbar_blue','nbar_nir_1','nbar_swir_2','nbar_swir_3','fmask'),\n",
    "                     group_by='solar_day',\n",
    "                     y=tuple(data['lat']),\n",
    "                     x=tuple(data['lon']),\n",
    "                     time=tuple(data['time']),\n",
    "                     resolution = (-10,10),\n",
    "                     output_crs='epsg:3577')\n",
    "\n",
    "\n",
    "        crs = ds_s2b.crs\n",
    "        affine = ds_s2b.affine\n",
    "        clear_pixels = [0,2,3]\n",
    "        clear_pixels_mask = xarray.DataArray(np.in1d(ds_s2b.fmask, clear_pixels).reshape(ds_s2b.fmask.shape), \n",
    "                                             dims=ds_s2b.fmask.dims, \n",
    "                                             coords=ds_s2b.fmask.coords)\n",
    "\n",
    "        ds_s2b = ds_s2b.where(clear_pixels_mask)\n",
    "        ds_s2b.attrs['crs'] = crs\n",
    "        ds_s2b.attrs['affine'] = affine\n",
    "\n",
    "        ds = xarray.merge([ds_s2a,ds_s2b])\n",
    "        ds.attrs['crs'] = crs\n",
    "        ds.attrs['affine'] = affine\n",
    "    except:\n",
    "        return xarray.DataArray([])\n",
    "    \n",
    "    return ds\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print('No Case Study Selected')\n",
    "    target_dataset_sent,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    \n",
    "    \n",
    "    if 'loaded' in locals():\n",
    "        if loaded['sent'] != config['load_id'] or loaded['sent'] is None:\n",
    "            print('Retrieving New Cube')\n",
    "            ds = load_into_cube_sentinel()\n",
    "            if len(ds) == 0:\n",
    "                print ('Selected spatial extent does not contain any indexed products')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "                target_dataset_sent,desc = None, 'Reload case study extent'\n",
    "            elif len(ds.time) < 2: \n",
    "                print ('Selected spatial extent only contains a single epoch')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "                target_dataset_sent,desc = None, 'Reload case study extent'\n",
    "\n",
    "            else:\n",
    "                target_dataset_sent,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "                loaded['sent'] = config['load_id']\n",
    "            \n",
    "    \n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "    print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset_sent\n",
    "    target_dataset_sent, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "labels = []\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "    \n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "        \n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = target_dataset_sent.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        \n",
    "        \n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "        \n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        \n",
    "        dataMasked = target_dataset_sent.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        try:\n",
    "            data_masked_mean = data_masked_mean.interpolate_na(dim = 'time', method = 'nearest')\n",
    "        except:\n",
    "            print('Unable to interpolate unknown values.')\n",
    "        \n",
    "        xarray.plot.plot(data_masked_mean, marker='*')\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "    \n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro sentinel_band_indices_app 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store sentinel_band_indices_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Landsat 8 Geomedians  \n",
    "%pylab notebook\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "if 'loaded' not in locals():\n",
    "    loaded = {}\n",
    "    loaded['sent'] = None\n",
    "    loaded['landsat8_geomed'] = None\n",
    "    loaded['landsat7_geomed'] = None\n",
    "    loaded['landsat5_geomed'] = None\n",
    "    loaded['landsat8_frac'] = None\n",
    "    loaded['landsat7_frac'] = None\n",
    "    loaded['landsat5how_frac'] = None\n",
    "    \n",
    "    \n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_geomedian(measurements = None, cloud_mask = False):\n",
    "\n",
    "    data = load_config(case_study)\n",
    "\n",
    "    ds = dc.load(product='ls8_nbart_geomedian_annual', \n",
    "                 measurements = ('red','green','blue','nir','swir1','swir2'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 resolution = (-25,25))\n",
    "\n",
    "    \n",
    "    return ds\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset_landsat8_geomed,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    \n",
    "    if 'loaded' in locals():\n",
    "        if loaded['landsat8_geomed'] != config['load_id'] or loaded['landsat8_geomed'] is None:\n",
    "            print ('Retrieving New Cube')\n",
    "            ds = load_into_cube_geomedian()\n",
    "            if len(ds) == 0:\n",
    "                print ('Selected spatial extent does not contain any indexed products')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "                target_dataset_sent,desc = None, 'Reload case study extent'\n",
    "            elif len(ds.time) < 2: \n",
    "                print ('Selected spatial extent only contains a single epoch')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "                target_dataset_sent,desc = None, 'Reload case study extent'\n",
    "\n",
    "            else:\n",
    "                target_dataset_landsat8_geomed,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "                loaded['landsat8_geomed'] = config['load_id']\n",
    "    \n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset_landsat8_geomed\n",
    "    target_dataset_landsat8_geomed, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "labels = []\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    #print (geo_json)\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = target_dataset_landsat8_geomed.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "       \n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        dataMasked = target_dataset_landsat8_geomed.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        #data_masked_mean.plot()\n",
    "\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "\n",
    "        xarray.plot.plot(data_masked_mean, marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro geomedian_landsat8_band_indices_app 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store geomedian_landsat8_band_indices_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Landsat 7 Geomedians  \n",
    "%pylab notebook\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "\n",
    "if 'loaded' not in locals():\n",
    "    loaded = {}\n",
    "    loaded['sent'] = None\n",
    "    loaded['landsat8_geomed'] = None\n",
    "    loaded['landsat7_geomed'] = None\n",
    "    loaded['landsat5_geomed'] = None\n",
    "    loaded['landsat8_frac'] = None\n",
    "    loaded['landsat7_frac'] = None\n",
    "    loaded['landsat5how_frac'] = None\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_geomedian(measurements = None, cloud_mask = False):\n",
    "\n",
    "    data = load_config(case_study)\n",
    "\n",
    "    ds = dc.load(product='ls7_nbart_geomedian_annual', \n",
    "                 measurements = ('red','green','blue','nir','swir1','swir2'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 resolution = (-25,25))\n",
    "\n",
    "    \n",
    "    return ds\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset_landsat7_geomed,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    \n",
    "    if 'loaded' in locals():\n",
    "        if loaded['landsat7_geomed'] != config['load_id'] or loaded['landsat7_geomed'] is None:\n",
    "            print ('Retrieving New Cube')\n",
    "            ds = load_into_cube_geomedian()\n",
    "            if len(ds) == 0:\n",
    "                print ('Selected spatial extent does not contain any indexed products')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "                target_dataset_sent,desc = None, 'Reload case study extent'\n",
    "            elif len(ds.time) < 2: \n",
    "                print ('Selected spatial extent only contains a single epoch')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "                target_dataset_sent,desc = None, 'Reload case study extent'\n",
    "            else:\n",
    "                target_dataset_landsat7_geomed,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "                loaded['landsat7_geomed'] = config['load_id']\n",
    "\n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset_landsat7_geomed\n",
    "    target_dataset_landsat7_geomed, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "labels = []\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    #print (geo_json)\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = target_dataset_landsat7_geomed.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "       \n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        dataMasked = target_dataset_landsat7_geomed.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        #data_masked_mean.plot()\n",
    "\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "\n",
    "        xarray.plot.plot(data_masked_mean, marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro geomedian_landsat7_band_indices_app 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store geomedian_landsat7_band_indices_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Landsat 5 Geomedians  \n",
    "%pylab notebook\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "if 'loaded' not in locals():\n",
    "    loaded = {}\n",
    "    loaded['sent'] = None\n",
    "    loaded['landsat8_geomed'] = None\n",
    "    loaded['landsat7_geomed'] = None\n",
    "    loaded['landsat5_geomed'] = None\n",
    "    loaded['landsat8_frac'] = None\n",
    "    loaded['landsat7_frac'] = None\n",
    "    loaded['landsat5how_frac'] = None\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_geomedian(measurements = None, cloud_mask = False):\n",
    "\n",
    "    data = load_config(case_study)\n",
    "\n",
    "    ds = dc.load(product='ls5_nbart_geomedian_annual',\n",
    "                 measurements = ('red','green','blue','nir','swir1','swir2'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 resolution = (-25,25))\n",
    "\n",
    "    \n",
    "    return ds\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    \n",
    "    if 'loaded' in locals():\n",
    "        if loaded['landsat5_geomed'] != config['load_id'] or loaded['landsat5_geomed'] is None:\n",
    "            print ('Retrieving New Cube')\n",
    "            ds = load_into_cube_geomedian()\n",
    "            if len(ds) == 0:\n",
    "                print ('Selected spatial extent does not contain any indexed products')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "                target_dataset_sent,desc = None, 'Reload case study extent'\n",
    "            elif len(ds.time)<2: \n",
    "                print ('Selected spatial extent only contains a single epoch')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "                target_dataset_sent,desc = None, 'Reload case study extent'\n",
    "            else:\n",
    "                target_dataset_landsat5_geomed,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "                loaded['landsat5_geomed'] = config['load_id']\n",
    "    \n",
    "    #ds = load_into_cube_geomedian()\n",
    "    #target_dataset,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "\n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset_landsat5_geomed\n",
    "    target_dataset_landsat5_geomed, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "labels = []\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    #print (geo_json)\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = target_dataset_landsat5_geomed.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "       \n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        dataMasked = target_dataset_landsat5_geomed.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        #data_masked_mean.plot()\n",
    "\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "\n",
    "        xarray.plot.plot(data_masked_mean, marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro geomedian_landsat5_band_indices_app 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store geomedian_landsat5_band_indices_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Fractional Cover Stack Plot Extent App\n",
    "%pylab notebook\n",
    "import xarray\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "#from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "from datacube import Datacube\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "if 'loaded' not in locals():\n",
    "    loaded = {}\n",
    "    loaded['sent'] = None\n",
    "    loaded['landsat8_geomed'] = None\n",
    "    loaded['landsat7_geomed'] = None\n",
    "    loaded['landsat5_geomed'] = None\n",
    "    loaded['landsat8_frac'] = None\n",
    "    loaded['landsat7_frac'] = None\n",
    "    loaded['landsat5how_frac'] = None\n",
    "    \n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_into_cube_fractional(measurements = None, cloud_mask = False):\n",
    "    try:\n",
    "        data = load_config(case_study)\n",
    "\n",
    "        global ds2\n",
    "        dc = Datacube()\n",
    "\n",
    "\n",
    "        ds1 = dc.load(product='ls8_fc_albers',\n",
    "                            latitude=tuple(data['lat']), \n",
    "                            longitude=tuple(data['lon']),\n",
    "                            time=tuple(data['time']), \n",
    "                            measurements = ['BS', 'PV', 'NPV'],\n",
    "                            #output_crs='epsg:3577',\n",
    "                            resolution = (-25,25))\n",
    "        print ('loaded FC')\n",
    "\n",
    "        ##To not overgrab wofs data lets use the minimum fractional cover date.\n",
    "        dates = data['time']\n",
    "        dates[0] = str(ds1.time.min().values)[:10]\n",
    "\n",
    "        ds_water = dc.load(product='wofs_albers',\n",
    "                           latitude=tuple(data['lat']),\n",
    "                           longitude=tuple(data['lon']),\n",
    "                           time=tuple(dates), \n",
    "                           output_crs='epsg:3577',\n",
    "                           resolution = (-25,25))\n",
    "\n",
    "        # Filter Fractional Cover values below 20% RMSe\n",
    "        #ds1 = ds2.where(ds2.UE.where(ds2.UE<=20.0))\n",
    "\n",
    "        # Mask with WOFS\n",
    "        wetwofl = masking.make_mask(ds_water, wet=True)\n",
    "        wetwofl_time = wetwofl.where(ds_water.time == ds1.time)\n",
    "        ds = ds1.where(ds1.time == ds_water.time)\n",
    "        ds = ds.where(wetwofl.water==False)\n",
    "        print ('loaded WOFL')\n",
    "    except:\n",
    "        return [xarray.DataArray([]),xarray.DataArray([])]\n",
    "\n",
    "    return [ds, wetwofl_time]\n",
    "\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "graph = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    desc = \"\"\n",
    "    print ('No Case Study Selected')\n",
    "else:\n",
    "\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "\n",
    "    if 'loaded' in locals():\n",
    "        if loaded['landsat8_frac'] != config['load_id'] or loaded['landsat8_frac'] is None:\n",
    "            print ('Retrieving New Cube')\n",
    "            ds, ds_water = load_into_cube_fractional()\n",
    "            #ds1 = ds.where(ds.UE.where(ds.UE<=20.0))\n",
    "            if len(ds) == 0:\n",
    "                print ('Selected spatial extent does not contain any indexed products')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "            elif len(ds.time < 2): \n",
    "                print ('Selected spatial extent only contains a single epoch')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "            else:\n",
    "\n",
    "                ds_area = (ds/100) * 625\n",
    "                ds_water_area = ds_water * 625\n",
    "                ds_all_raw = xarray.merge([ds_area,ds_water_area])\n",
    "                ds_all = ds_all_raw.fillna(0)\n",
    "                loaded['landsat8_frac'] = config['load_id']\n",
    "   \n",
    "    \n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "\n",
    "def onclick(event):\n",
    "    global timeOfInterest\n",
    "    timeOfInterest = event.xdata\n",
    "    time_slice = matplotlib.dates.num2date(timeOfInterest).date()\n",
    "    time_slice = str(time_slice)\n",
    "    time_slice = pd.to_datetime(time_slice, format='%Y-%m-%d')\n",
    "    label_html.value = '<b>Date selected from stack plot is ' + str(time_slice)[:10] + '</b>'\n",
    "    \n",
    "def display_extent(active):\n",
    "    if 'timeOfInterest' and 'dataMasked' in globals():\n",
    "\n",
    "        time_slice = matplotlib.dates.num2date(timeOfInterest).date()\n",
    "        time_slice = str(time_slice)\n",
    "        time_slice = pd.to_datetime(time_slice, format='%Y-%m-%d')\n",
    "\n",
    "        plot_graph = dataMasked.sel(time=[time_slice], method='nearest')\n",
    "\n",
    "        shape_arr = plot_graph.water.values.shape\n",
    "\n",
    "        a_b = np.zeros([shape_arr[1],shape_arr[2],4])\n",
    "        a_b[...,0] = plot_graph.water.values\n",
    "        a_b[...,1] = plot_graph.BS.values\n",
    "        a_b[...,2] = plot_graph.PV.values\n",
    "        a_b[...,3] = plot_graph.NPV.values\n",
    "\n",
    "\n",
    "        #plot_me = xarray.Dataset()\n",
    "        #plot_me.coords.update(plot_graph.isel(time=0).coords)\n",
    "        #plot_me['class'] = np.argmax(a_b, axis = 2)\n",
    "        plot_me = np.argmax(a_b, axis = 2)\n",
    "        mask = np.isnan(plot_graph.water.values)[0]\n",
    "        plot_me[mask] = -1\n",
    "        plot_me = plot_me[firstrow:lastrow,firstcol:lastcol]\n",
    "        cmap, norm = from_levels_and_colors([-0.5,0.5,1.5,2.5,3.5],['blue','red','green','orange'])\n",
    "\n",
    "        if plt.fignum_exists(datasetID + 1):\n",
    "            plt.figure(num= datasetID + 1, figsize=(10, 10))\n",
    "            plt.cla()\n",
    "\n",
    "            plt.imshow(plot_me,cmap=cmap, norm=norm)\n",
    "        else:\n",
    "            plt.figure(num= datasetID + 1, figsize=(10, 10))\n",
    "\n",
    "            plt.imshow(plot_me,cmap=cmap, norm=norm)\n",
    "\n",
    "            plt.title( 'Water Extent on' +  str(time_slice)[:10])\n",
    "\n",
    "            cbar = plt.colorbar(orientation = 'horizontal')       \n",
    "\n",
    "            cbar.ax.get_xaxis().set_ticks([])\n",
    "            for j, lab in enumerate(['Water','Bare Ground','Green Veg','Brown Veg']):\n",
    "                cbar.ax.text((2 * j + 1) / 8.0, 0.5, lab, ha='center', va='center')\n",
    "            cbar.ax.get_xaxis().labelpad = 10\n",
    "            cbar.ax.set_xlabel('classification')\n",
    "\n",
    "def plot_FC(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "    global ds\n",
    "    global dataMasked\n",
    "    global firstcol,firstrow,lastcol,lastrow\n",
    "\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = ds_all.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        data_masked_mean_raw = drill_cube.isel(x=0,y=0)\n",
    "        data_masked_mean = data_masked_mean_raw\n",
    "        \n",
    "        data_masked_mean_bare = data_masked_mean.BS\n",
    "        data_masked_mean_green_veg = data_masked_mean.PV\n",
    "        data_masked_mean_dead_veg = data_masked_mean.NPV\n",
    "        data_masked_mean_water = data_masked_mean.water\n",
    "        #global data_masked_mean_UE\n",
    "        #data_masked_mean_UE = data_masked_mean.UE\n",
    "\n",
    "        label = 'Point ' + str(datasetID)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "        geom_ogr = ogr.CreateGeometryFromJson(str(geom))\n",
    "\n",
    "        geom_area = geom_ogr.GetArea()\n",
    "        \n",
    "        \n",
    "        global mask\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        \n",
    "        total_area = mask.sum() * 625\n",
    "        #print (total_area,geom_area)\n",
    "        dataMasked = ds_all.where(mask)\n",
    "                \n",
    "        nan_mask = mask.astype('float')\n",
    "        nan_mask[~mask] = np.nan\n",
    "        \n",
    "        nans = np.isnan(nan_mask)\n",
    "        nancols = np.all(nans, axis=0) \n",
    "        nanrows = np.all(nans, axis=1) \n",
    "        \n",
    "        firstcol = nancols.argmin() \n",
    "        firstrow = nanrows.argmin() \n",
    "\n",
    "        lastcol = len(nancols) - nancols[::-1].argmin() # 8, last index where not NAN\n",
    "        lastrow = len(nanrows) - nanrows[::-1].argmin() # 10\n",
    "\n",
    "        \n",
    "        ###Confidence Mask not ready for use yet.\n",
    "        #confidence_masked = ds.UE.where(mask)\n",
    "        #confidence_masked_mean = confidence_masked.mean(dim = ['x','y'])\n",
    "        \n",
    "        data_masked_mean = dataMasked.sum(dim = ['x','y'])\n",
    "        #data_masked_mean.all = data_masked_mean.sum(dim = 'time')\n",
    "\n",
    "        data_masked_mean_filt = data_masked_mean.where(data_masked_mean<=total_area)\n",
    "        data_masked_mean_bare = data_masked_mean_filt.BS\n",
    "        data_masked_mean_green_veg = data_masked_mean_filt.PV\n",
    "        data_masked_mean_dead_veg = data_masked_mean_filt.NPV\n",
    "        data_masked_mean_water = data_masked_mean_filt.water\n",
    "        \n",
    "\n",
    "        \n",
    "        label = 'Polygon ' + str(datasetID)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "\n",
    "    get_pandas = data_masked_mean.to_dataframe()\n",
    "    get_pandas.rename(columns=lambda x: x + '_' + label, inplace=True)\n",
    "    get_pandas = get_pandas[get_pandas.columns.drop(list(get_pandas.filter(regex='UE')))]\n",
    "\n",
    "    output_pandas =  pd.concat([output_pandas,get_pandas],axis = 1)\n",
    "\n",
    "\n",
    "    #color_scheme = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    fig = plt.figure(num=datasetID + 1, figsize=(10, 5))\n",
    "    time_from = np.ravel(data_masked_mean.time)\n",
    "    \n",
    "    plt.ylabel('Area (m^2)')\n",
    "    color_scheme = '#ff7f0e', '#2ca02c', '#d62728', '#1f77b4'\n",
    "    plt.stackplot(time_from,data_masked_mean_dead_veg, \n",
    "                 data_masked_mean_green_veg, \n",
    "                  data_masked_mean_bare, \n",
    "                  data_masked_mean_water,\n",
    "                  colors = color_scheme,\n",
    "                  labels=['Brown Veg','Green Veg','Bare Ground','Water'])\n",
    "    plt.legend(loc='upper left')\n",
    "    fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "    #Plotting confidence on the same graph\n",
    "    #ax2 = plt.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    #color = 'tab:blue'\n",
    "    #ax2.set_ylabel('confidence', color=color)  # we already handled the x-label with ax1\n",
    "    #ax2.plot(time_from, confidence_masked_mean, color=color) \n",
    "    \n",
    "    plt.title('Fractional Cover Stack Plot ' + label )\n",
    "    plt.show()\n",
    "\n",
    "    datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "\n",
    "\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_FC)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "label_html = widgets.HTML(\n",
    "        value=\"<b>Date selected from stack plot is </b>\",\n",
    "        layout=widgets.Layout(flex='1 1 auto', width='auto'))\n",
    "\n",
    "\n",
    "\n",
    "button_plot =  widgets.Button(description='Plot Spatial Extent', \n",
    "               disabled=False,\n",
    "               button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "               tooltip='Click me', layout=widgets.Layout(flex='1 1 auto', width='auto'))\n",
    "\n",
    "button_plot.on_click(display_extent)\n",
    "\n",
    "\n",
    "plot_module = widgets.HBox([label_html, button_plot])\n",
    "\n",
    "\n",
    "\n",
    "pixel_drill = widgets.VBox([m3,graph,out,plot_module])\n",
    "\n",
    "pixel_drill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro fractional_cover_stack_plot_extentplot_app 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store fractional_cover_stack_plot_extentplot_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Fractional Cover Stack Plot App\n",
    "%pylab notebook\n",
    "import xarray\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "#from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "from datacube import Datacube\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "if 'loaded' not in locals():\n",
    "    loaded = {}\n",
    "    loaded['sent'] = None\n",
    "    loaded['landsat8_geomed'] = None\n",
    "    loaded['landsat7_geomed'] = None\n",
    "    loaded['landsat5_geomed'] = None\n",
    "    loaded['landsat8_frac'] = None\n",
    "    loaded['landsat7_frac'] = None\n",
    "    loaded['landsat5how_frac'] = None\n",
    "    \n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_into_cube_fractional(measurements = None, cloud_mask = False):\n",
    "    try:\n",
    "        data = load_config(case_study)\n",
    "\n",
    "        global ds2\n",
    "        dc = Datacube()\n",
    "\n",
    "\n",
    "        ds1 = dc.load(product='ls8_fc_albers',\n",
    "                            latitude=tuple(data['lat']), \n",
    "                            longitude=tuple(data['lon']),\n",
    "                            time=tuple(data['time']), \n",
    "                            measurements = ['BS', 'PV', 'NPV'],\n",
    "                            #output_crs='epsg:3577',\n",
    "                            resolution = (-25,25))\n",
    "        print ('loaded FC')\n",
    "\n",
    "        ##To not overgrab wofs data lets use the minimum fractional cover date.\n",
    "        dates = data['time']\n",
    "        dates[0] = str(ds1.time.min().values)[:10]\n",
    "\n",
    "        ds_water = dc.load(product='wofs_albers',\n",
    "                           latitude=tuple(data['lat']),\n",
    "                           longitude=tuple(data['lon']),\n",
    "                           time=tuple(dates), \n",
    "                           output_crs='epsg:3577',\n",
    "                           resolution = (-25,25))\n",
    "\n",
    "        # Filter Fractional Cover values below 20% RMSe\n",
    "        #ds1 = ds2.where(ds2.UE.where(ds2.UE<=20.0))\n",
    "\n",
    "        # Mask with WOFS\n",
    "        wetwofl = masking.make_mask(ds_water, wet=True)\n",
    "        wetwofl_time = wetwofl.where(ds_water.time == ds1.time)\n",
    "        ds = ds1.where(ds1.time == ds_water.time)\n",
    "        ds = ds.where(wetwofl.water==False)\n",
    "        print ('loaded WOFL')\n",
    "    except:\n",
    "        return [xarray.DataArray([]),xarray.DataArray([])]\n",
    "    return [ds, wetwofl_time]\n",
    "\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "graph = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    desc = \"\"\n",
    "    print ('No Case Study Selected')\n",
    "else:\n",
    "\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "\n",
    "    if 'loaded' in locals():\n",
    "        if loaded['landsat8_frac'] != config['load_id'] or loaded['landsat8_frac'] is None:\n",
    "            print ('Retrieving New Cube')\n",
    "            ds, ds_water = load_into_cube_fractional()\n",
    "            #ds1 = ds.where(ds.UE.where(ds.UE<=20.0))\n",
    "            if len(ds) == 0:\n",
    "                print ('Selected spatial extent does not contain any indexed products')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "            elif len(ds.time < 2): \n",
    "                print ('Selected spatial extent only contains a single epoch')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "            else:\n",
    "\n",
    "                ds_area = (ds/100) * 625\n",
    "                ds_water_area = ds_water * 625\n",
    "                ds_all_raw = xarray.merge([ds_area,ds_water_area])\n",
    "                ds_all = ds_all_raw.fillna(0)\n",
    "                loaded['landsat8_frac'] = config['load_id']\n",
    "   \n",
    "    \n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "\n",
    "def plot_FC(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "    global ds\n",
    "    global dataMasked\n",
    "    global firstcol,firstrow,lastcol,lastrow\n",
    "\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = ds_all.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        data_masked_mean_raw = drill_cube.isel(x=0,y=0)\n",
    "        data_masked_mean = data_masked_mean_raw\n",
    "        \n",
    "        data_masked_mean_bare = data_masked_mean.BS\n",
    "        data_masked_mean_green_veg = data_masked_mean.PV\n",
    "        data_masked_mean_dead_veg = data_masked_mean.NPV\n",
    "        data_masked_mean_water = data_masked_mean.water\n",
    "        #global data_masked_mean_UE\n",
    "        #data_masked_mean_UE = data_masked_mean.UE\n",
    "\n",
    "        label = 'Point ' + str(datasetID)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "        geom_ogr = ogr.CreateGeometryFromJson(str(geom))\n",
    "\n",
    "        geom_area = geom_ogr.GetArea()\n",
    "        \n",
    "        \n",
    "        global mask\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        \n",
    "        total_area = mask.sum() * 625\n",
    "        #print (total_area,geom_area)\n",
    "        dataMasked = ds_all.where(mask)\n",
    "                \n",
    "        nan_mask = mask.astype('float')\n",
    "        nan_mask[~mask] = np.nan\n",
    "        \n",
    "        nans = np.isnan(nan_mask)\n",
    "        nancols = np.all(nans, axis=0) \n",
    "        nanrows = np.all(nans, axis=1) \n",
    "        \n",
    "        firstcol = nancols.argmin() \n",
    "        firstrow = nanrows.argmin() \n",
    "\n",
    "        lastcol = len(nancols) - nancols[::-1].argmin() # 8, last index where not NAN\n",
    "        lastrow = len(nanrows) - nanrows[::-1].argmin() # 10\n",
    "\n",
    "        \n",
    "        ###Confidence Mask not ready for use yet.\n",
    "        #confidence_masked = ds.UE.where(mask)\n",
    "        #confidence_masked_mean = confidence_masked.mean(dim = ['x','y'])\n",
    "        \n",
    "        data_masked_mean = dataMasked.sum(dim = ['x','y'])\n",
    "        #data_masked_mean.all = data_masked_mean.sum(dim = 'time')\n",
    "\n",
    "        data_masked_mean_filt = data_masked_mean.where(data_masked_mean<=total_area)\n",
    "        data_masked_mean_bare = data_masked_mean_filt.BS\n",
    "        data_masked_mean_green_veg = data_masked_mean_filt.PV\n",
    "        data_masked_mean_dead_veg = data_masked_mean_filt.NPV\n",
    "        data_masked_mean_water = data_masked_mean_filt.water\n",
    "        \n",
    "\n",
    "        \n",
    "        label = 'Polygon ' + str(datasetID)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "\n",
    "    get_pandas = data_masked_mean.to_dataframe()\n",
    "    get_pandas.rename(columns=lambda x: x + '_' + label, inplace=True)\n",
    "    get_pandas = get_pandas[get_pandas.columns.drop(list(get_pandas.filter(regex='UE')))]\n",
    "\n",
    "    output_pandas =  pd.concat([output_pandas,get_pandas],axis = 1)\n",
    "\n",
    "\n",
    "    #color_scheme = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    fig = plt.figure(num=datasetID + 1, figsize=(10, 5))\n",
    "    time_from = np.ravel(data_masked_mean.time)\n",
    "    \n",
    "    plt.ylabel('Area (m^2)')\n",
    "    color_scheme = '#ff7f0e', '#2ca02c', '#d62728', '#1f77b4'\n",
    "    plt.stackplot(time_from,data_masked_mean_dead_veg, \n",
    "                 data_masked_mean_green_veg, \n",
    "                  data_masked_mean_bare, \n",
    "                  data_masked_mean_water,\n",
    "                  colors = color_scheme,\n",
    "                  labels=['Brown Veg','Green Veg','Bare Ground','Water'])\n",
    "    plt.legend(loc='upper left')\n",
    "    fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "    #Plotting confidence on the same graph\n",
    "    #ax2 = plt.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    #color = 'tab:blue'\n",
    "    #ax2.set_ylabel('confidence', color=color)  # we already handled the x-label with ax1\n",
    "    #ax2.plot(time_from, confidence_masked_mean, color=color) \n",
    "    \n",
    "    plt.title('Fractional Cover Stack Plot ' + label )\n",
    "    plt.show()\n",
    "\n",
    "    datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "\n",
    "\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_FC)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "\n",
    "\n",
    "button_plot =  widgets.Button(description='Plot Spatial Extent', \n",
    "               disabled=False,\n",
    "               button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "               tooltip='Click me', layout=widgets.Layout(flex='1 1 auto', width='auto'))\n",
    "\n",
    "button_plot.on_click(display_extent)\n",
    "\n",
    "pixel_drill = widgets.VBox([m3,graph,out])\n",
    "\n",
    "pixel_drill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro fractional_cover_stack_plot_app 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store fractional_cover_stack_plot_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "##Fractional Cover Line Plot App\n",
    "%pylab notebook\n",
    "import xarray\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "from datacube import Datacube\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "global first_plot\n",
    "first_plot = True\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "\n",
    "if 'loaded' not in locals():\n",
    "    loaded = {}\n",
    "    loaded['sent'] = None\n",
    "    loaded['landsat8_geomed'] = None\n",
    "    loaded['landsat7_geomed'] = None\n",
    "    loaded['landsat5_geomed'] = None\n",
    "    loaded['landsat8_frac'] = None\n",
    "    loaded['landsat7_frac'] = None\n",
    "    loaded['landsat5how_frac'] = None\n",
    "\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_into_cube_fractional(measurements = None, cloud_mask = False):\n",
    "    try:\n",
    "        data = load_config(case_study)\n",
    "\n",
    "        global ds2\n",
    "        dc = Datacube()\n",
    "\n",
    "        ds1 = dc.load(product='ls8_fc_albers',\n",
    "                            latitude=tuple(data['lat']), \n",
    "                            longitude=tuple(data['lon']),\n",
    "                            time=tuple(data['time']), \n",
    "                            measurements = ['BS', 'PV', 'NPV'],\n",
    "                            #output_crs='epsg:3577',\n",
    "                            resolution = (-25,25))\n",
    "        print ('loaded FC')\n",
    "\n",
    "        ##To not overgrab wofs data lets use the minimum fractional cover date.\n",
    "        dates = data['time']\n",
    "        dates[0] = str(ds1.time.min().values)[:10]\n",
    "\n",
    "        ds_water = dc.load(product='wofs_albers',\n",
    "                           latitude=tuple(data['lat']),\n",
    "                           longitude=tuple(data['lon']),\n",
    "                           time=tuple(dates), \n",
    "                           output_crs='epsg:3577',\n",
    "                           resolution = (-25,25))\n",
    "\n",
    "        # Filter Fractional Cover values below 20% RMSe\n",
    "\n",
    "        #ds1 = ds2.where(ds2.UE.where(ds2.UE<=20.0))\n",
    "\n",
    "        # Mask with WOFS\n",
    "        wetwofl = masking.make_mask(ds_water, wet=True)\n",
    "        wetwofl_time = wetwofl.where(ds_water.time == ds1.time)\n",
    "        ds = ds1.where(ds1.time == ds_water.time)\n",
    "        ds = ds.where(wetwofl.water==False)\n",
    "        print ('loaded WOFL')\n",
    "    except:\n",
    "        return [xarray.DataArray([]),xarray.DataArray([])]\n",
    "\n",
    "    return [ds, wetwofl_time]\n",
    "\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "graph = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    desc = \"\"\n",
    "    print ('No Case Study Selected')\n",
    "else:\n",
    "\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "\n",
    "    if 'loaded' in locals():\n",
    "        if loaded['landsat8_frac'] != config['load_id'] or loaded['landsat8_frac'] is None:\n",
    "            print ('Retrieving New Cube')\n",
    "            ds, ds_water = load_into_cube_fractional()\n",
    "            if len(ds) == 0:\n",
    "                print ('Selected spatial extent does not contain any indexed products')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "            elif len(ds.time < 2): \n",
    "                print ('Selected spatial extent only contains a single epoch')\n",
    "                print ('Please ensure at least two epochs are availble when reloading case study')\n",
    "            else:\n",
    "\n",
    "                #ds1 = ds.where(ds.UE.where(ds.UE<=20.0))\n",
    "\n",
    "                ds_area = (ds/100) * 625\n",
    "                ds_water_area = ds_water * 625\n",
    "                ds_all_raw = xarray.merge([ds_area,ds_water_area])\n",
    "                ds_all = ds_all_raw.fillna(0)\n",
    "                loaded['landsat8_frac'] = config['load_id']\n",
    "\n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "\n",
    "labels = []\n",
    "\n",
    "def plot_FC(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "    global ds\n",
    "    global first_plot\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = ds_all.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        data_masked_mean_raw = drill_cube.isel(x=0,y=0)\n",
    "        data_masked_mean = data_masked_mean_raw.resample(time='1M').median()\n",
    "\n",
    "        \n",
    "        data_masked_mean_bare = data_masked_mean.BS/625 * 100\n",
    "        data_masked_mean_green_veg = data_masked_mean.PV/625 * 100\n",
    "        data_masked_mean_dead_veg = data_masked_mean.NPV/625 * 100\n",
    "        data_masked_mean_water = data_masked_mean.water/625 * 100\n",
    "        #global data_masked_mean_UE\n",
    "        #data_masked_mean_UE = data_masked_mean.UE\n",
    "\n",
    "        label = 'Point ' + str(datasetID)\n",
    "        \n",
    "        labels.append(label)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "        geom_ogr = ogr.CreateGeometryFromJson(str(geom))\n",
    "\n",
    "        geom_area = geom_ogr.GetArea()\n",
    "        \n",
    "        \n",
    "        global mask\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        \n",
    "        total_area = mask.sum() * 625\n",
    "        dataMasked = ds_all.where(mask)\n",
    "        ###Confidence Mask not ready for use yet.\n",
    "        #confidence_masked = ds.UE.where(mask)\n",
    "        #confidence_masked_mean = confidence_masked.mean(dim = ['x','y'])\n",
    "        \n",
    "        data_masked_mean1 = dataMasked.sum(dim = ['x','y'])\n",
    "        \n",
    "        data_masked_mean = data_masked_mean1.resample(time='1M').median()\n",
    "        #data_masked_mean.all = data_masked_mean.sum(dim = 'time')\n",
    "\n",
    "        data_masked_mean_filt = data_masked_mean.where(data_masked_mean<=total_area)\n",
    "        data_masked_mean_bare = data_masked_mean_filt.BS / total_area * 100\n",
    "        data_masked_mean_green_veg = data_masked_mean_filt.PV /total_area * 100\n",
    "        data_masked_mean_dead_veg = data_masked_mean_filt.NPV /total_area * 100\n",
    "        data_masked_mean_water = data_masked_mean_filt.water / total_area * 100\n",
    "        \n",
    "\n",
    "        \n",
    "        label = 'Polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "\n",
    "    get_pandas = data_masked_mean.to_dataframe()\n",
    "    get_pandas.rename(columns=lambda x: x + '_' + label, inplace=True)\n",
    "    get_pandas = get_pandas[get_pandas.columns.drop(list(get_pandas.filter(regex='UE')))]\n",
    "\n",
    "    output_pandas =  pd.concat([output_pandas,get_pandas],axis = 1)\n",
    "\n",
    "    time_from = np.ravel(data_masked_mean.time)\n",
    "\n",
    "    if first_plot == True:\n",
    "        global f,axarr\n",
    "        \n",
    "        f, axarr = plt.subplots(4, sharey = True,figsize=(10, 15))\n",
    "        #f.suptitle('Fractional Cover Landsat 8')\n",
    "        \n",
    "        axarr[0].set_title( 'Bare Earth')\n",
    "        axarr[1].set_title( 'Green Veg')\n",
    "        axarr[2].set_title( 'Brown Veg')\n",
    "        axarr[3].set_title( 'Water')\n",
    "        \n",
    "        first_plot = False\n",
    "\n",
    "    \n",
    "    axarr[0].plot(time_from, data_masked_mean_bare.interpolate_na(dim = 'time', method = 'nearest'), marker ='*')\n",
    "    axarr[1].plot(time_from, data_masked_mean_green_veg.interpolate_na(dim = 'time', method = 'nearest'), marker ='*')\n",
    "    axarr[2].plot(time_from, data_masked_mean_dead_veg.interpolate_na(dim = 'time', method = 'nearest'), marker ='*')\n",
    "    axarr[3].plot(time_from, data_masked_mean_water.interpolate_na(dim = 'time', method = 'nearest'), marker ='*')\n",
    "    plt.legend(bbox_to_anchor=(0., -0.3, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "    \n",
    "    datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "\n",
    "\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_FC)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([m3,graph,out])\n",
    "\n",
    "pixel_drill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro fractional_cover_line_plot_app 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store fractional_cover_line_plot_app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
