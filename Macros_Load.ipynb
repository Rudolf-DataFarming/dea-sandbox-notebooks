{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipyleaflet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ea48e9555916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from ipyleaflet import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mMap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mMarker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipyleaflet'"
     ]
    }
   ],
   "source": [
    "from utils.utils import (\n",
    "    lat_lon_to_epsg)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datacube import Datacube\n",
    "import xarray\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout,HBox, VBox,Accordion,ToggleButtons,SelectionRangeSlider,Label\n",
    "import json\n",
    "import os\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "from traitlets import link\n",
    "import datetime\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "###need to add lat long and address search\n",
    "\n",
    "if 'center' not in locals():\n",
    "    center =[-34.42989,116.63979]\n",
    "    \n",
    "zoom = 13\n",
    "\n",
    "product_summary = widgets.Output(layout={'border': '1px solid black'})\n",
    "#dimensions = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "\n",
    "def generate_available_datasets_table():\n",
    "    products_from_cube = dc.list_products()\n",
    "    product_list = list(dc.list_products()['name'].values)\n",
    "    product_description = list(dc.list_products()['description'].values)\n",
    "    \n",
    "    build_table = []\n",
    "    \n",
    "    config = load_config('./configIndex.txt')\n",
    "    \n",
    "    for num, product in enumerate(product_list):\n",
    "        ds = dc.find_datasets(product=product,\n",
    "                 latitude=tuple(config['lat']),\n",
    "                 longitude=tuple(config['lon']),\n",
    "                 time=tuple(sorted(config['time']))\n",
    "                 )\n",
    "        captured_dates = []\n",
    "        for dataset in ds:\n",
    "            captured_dates.append(dataset.time.begin.date())\n",
    "        if len(captured_dates)>0:\n",
    "            number_epochs = len(set(captured_dates))\n",
    "            number_tiles =  len(captured_dates)\n",
    "\n",
    "            captured_dates_sorted = sorted(captured_dates)\n",
    "\n",
    "            start_date = captured_dates_sorted[0]\n",
    "            end_date = captured_dates_sorted[len(captured_dates_sorted)-1]\n",
    "\n",
    "\n",
    "            build_table.append([product,\n",
    "                               product_description[num],\n",
    "                               number_tiles,\n",
    "                               number_epochs,\n",
    "                               start_date,\n",
    "                               end_date\n",
    "                               ])\n",
    "    build_table = pd.DataFrame(build_table,columns = ['Product Name', \n",
    "                                                    'Product Description',\n",
    "                                                    'Number of Tiles',\n",
    "                                                    'Number of Epochs',\n",
    "                                                    'Start Date',\n",
    "                                                    'End Date'])\n",
    "    product_summary.clear_output()\n",
    "    with product_summary:\n",
    "        display(build_table)\n",
    "\n",
    "\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "    \n",
    "def update_config(filename,variable,value):\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        data[variable] = value\n",
    "        \n",
    "    os.remove(filename)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "m = Map(center=center, zoom=zoom)\n",
    "m2 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery,layout=m.layout)\n",
    "\n",
    "\n",
    "draw_control = DrawControl(rectangle={'shapeOptions': {'color': '#0000FF'}})\n",
    "draw_control2 = DrawControl(rectangle={'shapeOptions': {'color': '#0000FF'}})\n",
    "\n",
    "def handle_draw(self, action, geo_json):\n",
    "    if action == 'created':\n",
    "        m2.add_layer(GeoJSON(data=draw_control.last_draw))\n",
    "        draw_control2.last_draw =draw_control.last_draw\n",
    "        \n",
    "        lon_max = max([draw_control.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "        lon_min = min([draw_control.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "\n",
    "        lat_max = max([draw_control.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        lat_min = min([draw_control.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        EPSG = lat_lon_to_epsg(lat_max,lon_min)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #lat = {'lat' : (lat_max,lat_min),\n",
    "        #          'lon' : (lon_max,lon_min)}\n",
    "        update_config('./configIndex.txt',\n",
    "                 'output_crs',\n",
    "                 'epsg:' + EPSG)\n",
    "            \n",
    "        update_config('./configIndex.txt',\n",
    "                 'lat',\n",
    "                 (lat_max,lat_min))\n",
    "\n",
    "        update_config('./configIndex.txt',\n",
    "                 'lon',\n",
    "                 (lon_max,lon_min))\n",
    "        update_config('./configIndex.txt',\n",
    "              'geoJSON',\n",
    "              draw_control.last_draw\n",
    "             )\n",
    "\n",
    "    if action == 'deleted':\n",
    "        while len(m2.layers)>1:\n",
    "            m2.remove_layer(m2.layers[1])\n",
    "\n",
    "def handle_draw2(self, action, geo_json):\n",
    "    \n",
    "    if action == 'created':\n",
    "        m.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "        draw_control.last_draw =draw_control2.last_draw\n",
    "        \n",
    "        lon_max = max([draw_control2.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "        lon_min = min([draw_control2.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "\n",
    "        lat_max = max([draw_control2.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        lat_min = min([draw_control2.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        EPSG = lat_lon_to_epsg(lat_max,lon_min)\n",
    "        \n",
    "        update_config('./configIndex.txt',\n",
    "                 'output_crs',\n",
    "                 'epsg:' + EPSG)\n",
    "            \n",
    "        update_config('./configIndex.txt',\n",
    "                 'lat',\n",
    "                 (lat_max,lat_min))\n",
    "\n",
    "        update_config('./configIndex.txt',\n",
    "                 'lon',\n",
    "                 (lon_max,lon_min))\n",
    "        \n",
    "        update_config('./configIndex.txt',\n",
    "                      'geoJSON',\n",
    "                      draw_control2.last_draw\n",
    "                     )\n",
    "\n",
    "    if action == 'deleted':\n",
    "        while len(m.layers)>1:\n",
    "            m.remove_layer(m.layers[1])\n",
    "            \n",
    "#add handlers to draw controls  \n",
    "draw_control.on_draw(handle_draw)\n",
    "draw_control2.on_draw(handle_draw2)\n",
    "\n",
    "#add draw controls to maps\n",
    "m.add_control(draw_control)\n",
    "m2.add_control(draw_control2)\n",
    "\n",
    "#We can use link to synchronize traitlets of the two maps:\n",
    "\n",
    "map_center_link = link((m, 'center'), (m2, 'center'))\n",
    "map_zoom_link = link((m, 'zoom'), (m2, 'zoom'))\n",
    "\n",
    "dates = [datetime.date(1986,1,1) + datetime.timedelta(days =i) for i in range(1,12550)]\n",
    "date_range = SelectionRangeSlider(options=dates,\n",
    "                                          description = 'Date Range',\n",
    "                                          disabled=False,\n",
    "                                          layout = Layout(width='100%',height = '100px'))\n",
    "\n",
    "def date_func(b):\n",
    "    start_date,end_date = date_range.value\n",
    "    update_config('./configIndex.txt',\n",
    "                  'time',\n",
    "                  (start_date.strftime(\"%Y-%m-%d\"),\n",
    "                   end_date.strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "    generate_available_datasets_table()\n",
    "\n",
    "button = widgets.Button(description=\"Query Cube\",\n",
    "                       button_Style = 'success',\n",
    "                       layout=Layout(width='100%', height = '40px'))\n",
    "\n",
    "button.on_click(date_func)\n",
    "    \n",
    "case_study_select = VBox([m,m2,product_summary, date_range, button])\n",
    "    \n",
    "#date_range.observe(date_func, names = 'value')\n",
    "\n",
    "exe_load = True\n",
    "\n",
    "accordion = Accordion(children=[case_study_select])\n",
    "accordion.set_title(0, 'Select Case Study')\n",
    "accordion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro select_case_study_area 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store select_case_study_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab notebook\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_sentinal(measurements = None, cloud_mask = False):\n",
    "\n",
    "    data = load_config(case_study)\n",
    "    ds_s2a = dc.load(product='s2a_nrt_granule', \n",
    "                 measurements = ('nbar_red','nbar_green','nbar_blue','nbar_nir_1','nbar_swir_2','nbar_swir_3','fmask'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 resolution = (-25,25),\n",
    "                 output_crs='epsg:3577')\n",
    "    \n",
    "    \n",
    "    crs = ds_s2a.crs\n",
    "    affine = ds_s2a.affine\n",
    "    \n",
    "    \n",
    "    clear_pixels = [0,2,3]\n",
    "    clear_pixels_mask = xarray.DataArray(np.in1d(ds_s2a.fmask, clear_pixels).reshape(ds_s2a.fmask.shape), \n",
    "                                         dims=ds_s2a.fmask.dims, \n",
    "                                         coords=ds_s2a.fmask.coords)\n",
    "                     \n",
    "    ds_s2a = ds_s2a.where(clear_pixels_mask)\n",
    "        \n",
    "    ds_s2a.attrs['crs'] = crs\n",
    "    ds_s2a.attrs['affine'] = affine\n",
    "\n",
    "    ds_s2b = dc.load(product='s2b_nrt_granule', \n",
    "                 measurements = ('nbar_red','nbar_green','nbar_blue','nbar_nir_1','nbar_swir_2','nbar_swir_3','fmask'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 resolution = (-25,25),\n",
    "                 output_crs='epsg:3577')\n",
    "    \n",
    "    \n",
    "    crs = ds_s2b.crs\n",
    "    affine = ds_s2b.affine\n",
    "    clear_pixels = [0,2,3]\n",
    "    clear_pixels_mask = xarray.DataArray(np.in1d(ds_s2b.fmask, clear_pixels).reshape(ds_s2b.fmask.shape), \n",
    "                                         dims=ds_s2b.fmask.dims, \n",
    "                                         coords=ds_s2b.fmask.coords)\n",
    "    \n",
    "    ds_s2b = ds_s2b.where(clear_pixels_mask)\n",
    "    ds_s2b.attrs['crs'] = crs\n",
    "    ds_s2b.attrs['affine'] = affine\n",
    "    \n",
    "    ds = xarray.merge([ds_s2a,ds_s2b])\n",
    "    ds.attrs['crs'] = crs\n",
    "    ds.attrs['affine'] = affine\n",
    "    \n",
    "    \n",
    "    return ds\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    ds = load_into_cube_sentinal()\n",
    "    target_dataset,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "\n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset\n",
    "    target_dataset, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "labels = []\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "    \n",
    "    #print (geo_json)\n",
    "    \n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "        \n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = target_dataset.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        \n",
    "        \n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "        \n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        \n",
    "        dataMasked = target_dataset.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        try:\n",
    "            data_masked_mean = data_masked_mean.interpolate_na(dim = 'time', method = 'nearest')\n",
    "        except:\n",
    "            print ('Unable to interpolate unknown values.')\n",
    "        \n",
    "        xarray.plot.plot(data_masked_mean, marker='*')\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "    \n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro sentinel_band_indices_app 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store sentinel_band_indices_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Landsat 8 Geomedians  \n",
    "%pylab notebook\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_geomedian(measurements = None, cloud_mask = False):\n",
    "\n",
    "    data = load_config(case_study)\n",
    "\n",
    "    ds = dc.load(product='ls8_nbart_geomedian_annual', \n",
    "                 measurements = ('red','green','blue','nir','swir1','swir2'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 resolution = (-25,25))\n",
    "\n",
    "    \n",
    "    return ds\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    ds = load_into_cube_geomedian()\n",
    "    target_dataset,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "\n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset\n",
    "    target_dataset, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "labels = []\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    #print (geo_json)\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = target_dataset.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "       \n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        dataMasked = target_dataset.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        #data_masked_mean.plot()\n",
    "\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "\n",
    "        xarray.plot.plot(data_masked_mean, marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro geomedian_landsat8_band_indices_app 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store geomedian_landsat8_band_indices_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Landsat 7 Geomedians  \n",
    "%pylab notebook\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_geomedian(measurements = None, cloud_mask = False):\n",
    "\n",
    "    data = load_config(case_study)\n",
    "\n",
    "    ds = dc.load(product='ls7_nbart_geomedian_annual', \n",
    "                 measurements = ('red','green','blue','nir','swir1','swir2'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 resolution = (-25,25))\n",
    "\n",
    "    \n",
    "    return ds\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    ds = load_into_cube_geomedian()\n",
    "    target_dataset,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "\n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset\n",
    "    target_dataset, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "labels = []\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    #print (geo_json)\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = target_dataset.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "       \n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        dataMasked = target_dataset.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        #data_masked_mean.plot()\n",
    "\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "\n",
    "        xarray.plot.plot(data_masked_mean, marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro geomedian_landsat7_band_indices_app 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store geomedian_landsat7_band_indices_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Landsat 5 Geomedians  \n",
    "%pylab notebook\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_geomedian(measurements = None, cloud_mask = False):\n",
    "\n",
    "    data = load_config(case_study)\n",
    "\n",
    "    ds = dc.load(product='ls5_nbart_geomedian_annual', \n",
    "                 measurements = ('red','green','blue','nir','swir1','swir2'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 resolution = (-25,25))\n",
    "\n",
    "    \n",
    "    return ds\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    ds = load_into_cube_geomedian()\n",
    "    target_dataset,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "\n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset\n",
    "    target_dataset, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "labels = []\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    #print (geo_json)\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = target_dataset.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "       \n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        dataMasked = target_dataset.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        #data_masked_mean.plot()\n",
    "\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "\n",
    "        xarray.plot.plot(data_masked_mean, marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro geomedian_landsat5_band_indices_app 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store geomedian_landsat5_band_indices_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Fractional Cover Stack Plot App\n",
    "%pylab notebook\n",
    "import xarray\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "from datacube import Datacube\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_into_cube_fractional(measurements = None, cloud_mask = False):\n",
    "\n",
    "    data = load_config(case_study)\n",
    "\n",
    "    global ds2\n",
    "    dc = Datacube()\n",
    "\n",
    "\n",
    "    ds1 = dc.load(product='ls8_fc_albers', \n",
    "                        group_by='solar_day', \n",
    "                        latitude=tuple(data['lat']), \n",
    "                        longitude=tuple(data['lon']),\n",
    "                        time=tuple(data['time']), \n",
    "                        measurements = ['BS', 'PV', 'NPV'],\n",
    "                        #output_crs='epsg:3577',\n",
    "                        resolution = (-25,25))\n",
    "    print ('loaded FC')\n",
    "    \n",
    "    ##To not overgrab wofs data lets use the minimum fractional cover date.\n",
    "    dates = data['time']\n",
    "    dates[0] = str(ds1.time.min().values)[:10]\n",
    "\n",
    "    ds_water = dc.load(product='wofs_albers', \n",
    "                       group_by='solar_day',\n",
    "                       latitude=tuple(data['lat']),\n",
    "                       longitude=tuple(data['lon']),\n",
    "                       time=tuple(dates), \n",
    "                       output_crs='epsg:3577',\n",
    "                       resolution = (-25,25))\n",
    "\n",
    "    # Filter Fractional Cover values below 20% RMSe\n",
    "    #ds1 = ds2.where(ds2.UE.where(ds2.UE<=20.0))\n",
    "    \n",
    "    # Mask with WOFS\n",
    "    wetwofl = masking.make_mask(ds_water, wet=True)\n",
    "    wetwofl_time = wetwofl.where(ds_water.time == ds1.time)\n",
    "    ds = ds1.where(ds1.time == ds_water.time)\n",
    "    ds = ds.where(wetwofl.water==False)\n",
    "    print ('loaded WOFL')\n",
    "\n",
    "    return [ds, wetwofl_time]\n",
    "\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "graph = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    desc = \"\"\n",
    "    print ('No Case Study Selected')\n",
    "else:\n",
    "\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "\n",
    "    ds, ds_water = load_into_cube_fractional()\n",
    "    #ds1 = ds.where(ds.UE.where(ds.UE<=20.0))\n",
    "\n",
    "    ds_area = (ds/100) * 625\n",
    "    ds_water_area = ds_water * 625\n",
    "    ds_all_raw = xarray.merge([ds_area,ds_water_area])\n",
    "    ds_all = ds_all_raw.fillna(0)\n",
    "    \n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "\n",
    "\n",
    "def plot_FC(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "    global ds\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = ds_all.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        data_masked_mean_raw = drill_cube.isel(x=0,y=0)\n",
    "        data_masked_mean = data_masked_mean_raw\n",
    "        \n",
    "        data_masked_mean_bare = data_masked_mean.BS\n",
    "        data_masked_mean_green_veg = data_masked_mean.PV\n",
    "        data_masked_mean_dead_veg = data_masked_mean.NPV\n",
    "        data_masked_mean_water = data_masked_mean.water\n",
    "        #global data_masked_mean_UE\n",
    "        #data_masked_mean_UE = data_masked_mean.UE\n",
    "\n",
    "        label = 'Point ' + str(datasetID)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "        geom_ogr = ogr.CreateGeometryFromJson(str(geom))\n",
    "\n",
    "        geom_area = geom_ogr.GetArea()\n",
    "        \n",
    "        \n",
    "        global mask\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        \n",
    "        total_area = mask.sum() * 625\n",
    "        print (total_area,geom_area)\n",
    "        dataMasked = ds_all.where(mask)\n",
    "        ###Confidence Mask not ready for use yet.\n",
    "        #confidence_masked = ds.UE.where(mask)\n",
    "        #confidence_masked_mean = confidence_masked.mean(dim = ['x','y'])\n",
    "        \n",
    "        data_masked_mean = dataMasked.sum(dim = ['x','y'])\n",
    "        #data_masked_mean.all = data_masked_mean.sum(dim = 'time')\n",
    "\n",
    "        data_masked_mean_filt = data_masked_mean.where(data_masked_mean<=total_area)\n",
    "        data_masked_mean_bare = data_masked_mean_filt.BS\n",
    "        data_masked_mean_green_veg = data_masked_mean_filt.PV\n",
    "        data_masked_mean_dead_veg = data_masked_mean_filt.NPV\n",
    "        data_masked_mean_water = data_masked_mean_filt.water\n",
    "        \n",
    "\n",
    "        \n",
    "        label = 'Polygon ' + str(datasetID)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "\n",
    "    get_pandas = data_masked_mean.to_dataframe()\n",
    "    get_pandas.rename(columns=lambda x: x + '_' + label, inplace=True)\n",
    "    get_pandas = get_pandas[get_pandas.columns.drop(list(get_pandas.filter(regex='UE')))]\n",
    "\n",
    "    output_pandas =  pd.concat([output_pandas,get_pandas],axis = 1)\n",
    "\n",
    "\n",
    "    #color_scheme = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    plt.figure(num=datasetID, figsize=(10, 5))\n",
    "    time_from = np.ravel(data_masked_mean.time)\n",
    "    \n",
    "    plt.ylabel('Area (m^2)')\n",
    "    color_scheme = '#ff7f0e', '#2ca02c', '#d62728', '#1f77b4'\n",
    "    plt.stackplot(time_from,data_masked_mean_dead_veg, \n",
    "                 data_masked_mean_green_veg, \n",
    "                  data_masked_mean_bare, \n",
    "                  data_masked_mean_water,\n",
    "                  colors = color_scheme,\n",
    "                  labels=['Dead Veg','Green Veg','Bare Ground','Water'])\n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    #Plotting confidence on the same graph\n",
    "    #ax2 = plt.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    #color = 'tab:blue'\n",
    "    #ax2.set_ylabel('confidence', color=color)  # we already handled the x-label with ax1\n",
    "    #ax2.plot(time_from, confidence_masked_mean, color=color) \n",
    "    \n",
    "    plt.title('Fractional Cover Stack Plot ' + label )\n",
    "    plt.show()\n",
    "\n",
    "    datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "\n",
    "\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_FC)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([m3,graph,out])\n",
    "\n",
    "pixel_drill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro fractional_cover_stack_plot_app 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store fractional_cover_stack_plot_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "##Fractional Cover Line Plot App\n",
    "%pylab notebook\n",
    "import xarray\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "from datacube import Datacube\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "global first_plot\n",
    "first_plot = True\n",
    "\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_into_cube_fractional(measurements = None, cloud_mask = False):\n",
    "\n",
    "    data = load_config(case_study)\n",
    "\n",
    "    global ds2\n",
    "    dc = Datacube()\n",
    "\n",
    "    ds1 = dc.load(product='ls8_fc_albers', \n",
    "                        group_by='solar_day', \n",
    "                        latitude=tuple(data['lat']), \n",
    "                        longitude=tuple(data['lon']),\n",
    "                        time=tuple(data['time']), \n",
    "                        measurements = ['BS', 'PV', 'NPV'],\n",
    "                        #output_crs='epsg:3577',\n",
    "                        resolution = (-25,25))\n",
    "    print ('loaded FC')\n",
    "    \n",
    "    ##To not overgrab wofs data lets use the minimum fractional cover date.\n",
    "    dates = data['time']\n",
    "    dates[0] = str(ds1.time.min().values)[:10]\n",
    "\n",
    "    ds_water = dc.load(product='wofs_albers', \n",
    "                       group_by='solar_day',\n",
    "                       latitude=tuple(data['lat']),\n",
    "                       longitude=tuple(data['lon']),\n",
    "                       time=tuple(dates), \n",
    "                       output_crs='epsg:3577',\n",
    "                       resolution = (-25,25))\n",
    "    \n",
    "    # Filter Fractional Cover values below 20% RMSe\n",
    "    \n",
    "    #ds1 = ds2.where(ds2.UE.where(ds2.UE<=20.0))\n",
    "    \n",
    "    # Mask with WOFS\n",
    "    wetwofl = masking.make_mask(ds_water, wet=True)\n",
    "    wetwofl_time = wetwofl.where(ds_water.time == ds1.time)\n",
    "    ds = ds1.where(ds1.time == ds_water.time)\n",
    "    ds = ds.where(wetwofl.water==False)\n",
    "    print ('loaded WOFL')\n",
    "\n",
    "    return [ds, wetwofl_time]\n",
    "\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "graph = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    desc = \"\"\n",
    "    print ('No Case Study Selected')\n",
    "else:\n",
    "\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "\n",
    "    ds, ds_water = load_into_cube_fractional()\n",
    "    #ds1 = ds.where(ds.UE.where(ds.UE<=20.0))\n",
    "\n",
    "    ds_area = (ds/100) * 625\n",
    "    ds_water_area = ds_water * 625\n",
    "    ds_all_raw = xarray.merge([ds_area,ds_water_area])\n",
    "    ds_all = ds_all_raw.fillna(0)\n",
    "    \n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "EPSG = 3577\n",
    "\n",
    "labels = []\n",
    "\n",
    "def plot_FC(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "    global ds\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = ds_all.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        data_masked_mean_raw = drill_cube.isel(x=0,y=0)\n",
    "        data_masked_mean = data_masked_mean_raw.resample(time='1M').median()\n",
    "\n",
    "        \n",
    "        data_masked_mean_bare = data_masked_mean.BS/625 * 100\n",
    "        data_masked_mean_green_veg = data_masked_mean.PV/625 * 100\n",
    "        data_masked_mean_dead_veg = data_masked_mean.NPV/625 * 100\n",
    "        data_masked_mean_water = data_masked_mean.water/625 * 100\n",
    "        #global data_masked_mean_UE\n",
    "        #data_masked_mean_UE = data_masked_mean.UE\n",
    "\n",
    "        label = 'Point ' + str(datasetID)\n",
    "        \n",
    "        labels.append(label)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "        geom_ogr = ogr.CreateGeometryFromJson(str(geom))\n",
    "\n",
    "        geom_area = geom_ogr.GetArea()\n",
    "        \n",
    "        \n",
    "        global mask\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        \n",
    "        total_area = mask.sum() * 625\n",
    "        print (total_area,geom_area)\n",
    "        dataMasked = ds_all.where(mask)\n",
    "        ###Confidence Mask not ready for use yet.\n",
    "        #confidence_masked = ds.UE.where(mask)\n",
    "        #confidence_masked_mean = confidence_masked.mean(dim = ['x','y'])\n",
    "        \n",
    "        data_masked_mean1 = dataMasked.sum(dim = ['x','y'])\n",
    "        \n",
    "        data_masked_mean = data_masked_mean1.resample(time='1M').median()\n",
    "        #data_masked_mean.all = data_masked_mean.sum(dim = 'time')\n",
    "\n",
    "        data_masked_mean_filt = data_masked_mean.where(data_masked_mean<=total_area)\n",
    "        data_masked_mean_bare = data_masked_mean_filt.BS / total_area * 100\n",
    "        data_masked_mean_green_veg = data_masked_mean_filt.PV /total_area * 100\n",
    "        data_masked_mean_dead_veg = data_masked_mean_filt.NPV /total_area * 100\n",
    "        data_masked_mean_water = data_masked_mean_filt.water / total_area * 100\n",
    "        \n",
    "\n",
    "        \n",
    "        label = 'Polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "\n",
    "\n",
    "    get_pandas = data_masked_mean.to_dataframe()\n",
    "    get_pandas.rename(columns=lambda x: x + '_' + label, inplace=True)\n",
    "    get_pandas = get_pandas[get_pandas.columns.drop(list(get_pandas.filter(regex='UE')))]\n",
    "\n",
    "    output_pandas =  pd.concat([output_pandas,get_pandas],axis = 1)\n",
    "\n",
    "    time_from = np.ravel(data_masked_mean.time)\n",
    "\n",
    "    if first_plot:\n",
    "        global f, axarr\n",
    "        \n",
    "        f, axarr = plt.subplots(4, sharey = True,figsize=(10, 15))\n",
    "        \n",
    "        axarr[0].set_title('Bare Earth')\n",
    "        axarr[1].set_title('Green Veg')\n",
    "        axarr[2].set_title('Brown Veg')\n",
    "        axarr[3].set_title('Water')\n",
    "        \n",
    "        first_plot = False\n",
    "\n",
    "    \n",
    "    axarr[0].plot(time_from, data_masked_mean_bare.interpolate_na(dim = 'time', method = 'nearest'), marker ='*')\n",
    "    axarr[1].plot(time_from, data_masked_mean_green_veg.interpolate_na(dim = 'time', method = 'nearest'), marker ='*')\n",
    "    axarr[2].plot(time_from, data_masked_mean_dead_veg.interpolate_na(dim = 'time', method = 'nearest'), marker ='*')\n",
    "    axarr[3].plot(time_from, data_masked_mean_water.interpolate_na(dim = 'time', method = 'nearest'), marker ='*')\n",
    "    plt.legend(bbox_to_anchor=(0., -0.3, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "    \n",
    "    datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "\n",
    "\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_FC)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([m3,graph,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro fractional_cover_line_plot_app 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store fractional_cover_line_plot_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Landsat 5 Geomedians  \n",
    "#%pylab notebook\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_aws_landsat8(measurements = None, cloud_mask = False):\n",
    "\n",
    "    def lat_lon_to_epsg(lat_max, lon_min):\n",
    "        return str(int(32700 - round((45 + lat_max) / 90, 0) * 100 + round((183 + lon_min) / 6, 0)))\n",
    "\n",
    "    \n",
    "    data = load_config(case_study)\n",
    "\n",
    "       \n",
    "    lats= data['lat']\n",
    "    longs= data['lon']\n",
    "    global EPSG\n",
    "    EPSG = lat_lon_to_epsg(lats[1],longs[0])\n",
    "    \n",
    "    ds = dc.load(product='ls8_level1_usgs', \n",
    "                 measurements = ('red','green','blue','nir','swir1','swir2'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 output_crs='epsg:' + EPSG,\n",
    "                 resolution = (-25,25))\n",
    "\n",
    "    \n",
    "    return ds\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    #ds = load_into_cube_aws_landsat8()\n",
    "    target_dataset,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "\n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset\n",
    "    target_dataset, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "#EPSG = 3577\n",
    "labels = []\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    #print (geo_json)\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,EPSG)\n",
    "        drill_cube = target_dataset.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "       \n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "        STOP\n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],EPSG)\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        dataMasked = target_dataset.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        #data_masked_mean.plot()\n",
    "\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "\n",
    "        xarray.plot.plot(data_masked_mean, marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
