{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.utils import (\n",
    "    lat_lon_to_epsg)\n",
    "import uuid\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datacube import Datacube\n",
    "import xarray\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout,HBox, VBox,Accordion,ToggleButtons,SelectionRangeSlider,Label\n",
    "import json\n",
    "import os\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "from traitlets import link\n",
    "import datetime\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "###need to add lat long and address search\n",
    "\n",
    "if 'center' not in locals():\n",
    "    center =[-34.42989,116.63979]\n",
    "    \n",
    "zoom = 2\n",
    "\n",
    "product_summary = widgets.Output(layout={'border': '1px solid black'})\n",
    "#dimensions = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "\n",
    "def generate_available_datasets_table():\n",
    "    products_from_cube = dc.list_products()\n",
    "    product_list = list(dc.list_products()['name'].values)\n",
    "    product_description = list(dc.list_products()['description'].values)\n",
    "    \n",
    "    build_table = []\n",
    "    \n",
    "    config = load_config('./configIndex.txt')\n",
    "    \n",
    "    for num, product in enumerate(product_list):\n",
    "        ds = dc.find_datasets(product=product,\n",
    "                 latitude=tuple(config['lat']),\n",
    "                 longitude=tuple(config['lon']),\n",
    "                 time=tuple(sorted(config['time']))\n",
    "                 )\n",
    "        captured_dates = []\n",
    "        for dataset in ds:\n",
    "            captured_dates.append(dataset.time.begin.date())\n",
    "        if len(captured_dates)>0:\n",
    "            number_epochs = len(set(captured_dates))\n",
    "            number_tiles =  len(captured_dates)\n",
    "\n",
    "            captured_dates_sorted = sorted(captured_dates)\n",
    "\n",
    "            start_date = captured_dates_sorted[0]\n",
    "            end_date = captured_dates_sorted[len(captured_dates_sorted)-1]\n",
    "\n",
    "\n",
    "            build_table.append([product,\n",
    "                               product_description[num],\n",
    "                               number_tiles,\n",
    "                               number_epochs,\n",
    "                               start_date,\n",
    "                               end_date\n",
    "                               ])\n",
    "    build_table = pd.DataFrame(build_table,columns = ['Product Name', \n",
    "                                                    'Product Description',\n",
    "                                                    'Number of Tiles',\n",
    "                                                    'Number of Epochs',\n",
    "                                                    'Start Date',\n",
    "                                                    'End Date'])\n",
    "    product_summary.clear_output()\n",
    "    with product_summary:\n",
    "        display(build_table)\n",
    "\n",
    "\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "    \n",
    "def update_config(filename,variable,value):\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        data[variable] = value\n",
    "        \n",
    "    os.remove(filename)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "m = Map(center=center, zoom=zoom)\n",
    "m2 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery,layout=m.layout)\n",
    "\n",
    "\n",
    "draw_control = DrawControl(rectangle={'shapeOptions': {'color': '#0000FF'}})\n",
    "draw_control2 = DrawControl(rectangle={'shapeOptions': {'color': '#0000FF'}})\n",
    "\n",
    "def handle_draw(self, action, geo_json):\n",
    "    if action == 'created':\n",
    "        m2.add_layer(GeoJSON(data=draw_control.last_draw))\n",
    "        draw_control2.last_draw =draw_control.last_draw\n",
    "        \n",
    "        lon_max = max([draw_control.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "        lon_min = min([draw_control.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "\n",
    "        lat_max = max([draw_control.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        lat_min = min([draw_control.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        EPSG = lat_lon_to_epsg(lat_max,lon_min)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #lat = {'lat' : (lat_max,lat_min),\n",
    "        #          'lon' : (lon_max,lon_min)}\n",
    "        update_config('./configIndex.txt',\n",
    "                 'output_crs',\n",
    "                 'epsg:' + EPSG)\n",
    "            \n",
    "        update_config('./configIndex.txt',\n",
    "                 'lat',\n",
    "                 (lat_max,lat_min))\n",
    "\n",
    "        update_config('./configIndex.txt',\n",
    "                 'lon',\n",
    "                 (lon_max,lon_min))\n",
    "        update_config('./configIndex.txt',\n",
    "              'geoJSON',\n",
    "              draw_control.last_draw\n",
    "             )\n",
    "        update_config('./configIndex.txt',\n",
    "              'load_id',\n",
    "              str(uuid.uuid4())\n",
    "             )\n",
    "\n",
    "\n",
    "    if action == 'deleted':\n",
    "        while len(m2.layers)>1:\n",
    "            m2.remove_layer(m2.layers[1])\n",
    "\n",
    "def handle_draw2(self, action, geo_json):\n",
    "    \n",
    "    if action == 'created':\n",
    "        m.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "        draw_control.last_draw =draw_control2.last_draw\n",
    "        \n",
    "        lon_max = max([draw_control2.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "        lon_min = min([draw_control2.last_draw['geometry']['coordinates'][0][0][0],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][0]])\n",
    "\n",
    "        lat_max = max([draw_control2.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        lat_min = min([draw_control2.last_draw['geometry']['coordinates'][0][0][1],\n",
    "                       draw_control2.last_draw['geometry']['coordinates'][0][2][1]])\n",
    "        EPSG = lat_lon_to_epsg(lat_max,lon_min)\n",
    "        \n",
    "        update_config('./configIndex.txt',\n",
    "                 'output_crs',\n",
    "                 'epsg:' + EPSG)\n",
    "            \n",
    "        update_config('./configIndex.txt',\n",
    "                 'lat',\n",
    "                 (lat_max,lat_min))\n",
    "\n",
    "        update_config('./configIndex.txt',\n",
    "                 'lon',\n",
    "                 (lon_max,lon_min))\n",
    "        \n",
    "        update_config('./configIndex.txt',\n",
    "                      'geoJSON',\n",
    "                      draw_control2.last_draw\n",
    "                     )\n",
    "        update_config('./configIndex.txt',\n",
    "              'load_id',\n",
    "              str(uuid.uuid4())\n",
    "             )\n",
    "\n",
    "\n",
    "    if action == 'deleted':\n",
    "        while len(m.layers)>1:\n",
    "            m.remove_layer(m.layers[1])\n",
    "            \n",
    "#add handlers to draw controls  \n",
    "draw_control.on_draw(handle_draw)\n",
    "draw_control2.on_draw(handle_draw2)\n",
    "\n",
    "#add draw controls to maps\n",
    "m.add_control(draw_control)\n",
    "m2.add_control(draw_control2)\n",
    "\n",
    "#We can use link to synchronize traitlets of the two maps:\n",
    "\n",
    "map_center_link = link((m, 'center'), (m2, 'center'))\n",
    "map_zoom_link = link((m, 'zoom'), (m2, 'zoom'))\n",
    "\n",
    "dates = [datetime.date(1986,1,1) + datetime.timedelta(days =i) for i in range(1,12550)]\n",
    "date_range = SelectionRangeSlider(options=dates,\n",
    "                                          description = 'Date Range',\n",
    "                                          disabled=False,\n",
    "                                          layout = Layout(width='100%',height = '100px'))\n",
    "\n",
    "def date_func(b):\n",
    "    start_date,end_date = date_range.value\n",
    "    update_config('./configIndex.txt',\n",
    "                  'time',\n",
    "                  (start_date.strftime(\"%Y-%m-%d\"),\n",
    "                   end_date.strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "    generate_available_datasets_table()\n",
    "\n",
    "button = widgets.Button(description=\"Query Cube\",\n",
    "                       button_Style = 'success',\n",
    "                       layout=Layout(width='100%', height = '40px'))\n",
    "\n",
    "button.on_click(date_func)\n",
    "    \n",
    "case_study_select = VBox([m,m2,product_summary, date_range, button])\n",
    "    \n",
    "#date_range.observe(date_func, names = 'value')\n",
    "\n",
    "exe_load = True\n",
    "\n",
    "accordion = Accordion(children=[case_study_select])\n",
    "accordion.set_title(0, 'Select Case Study')\n",
    "accordion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro select_case_study_area 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store select_case_study_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Landsat 8 AWS\n",
    "%pylab notebook\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "from utils import BandIndices\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_aws_landsat8(measurements = None, cloud_mask = False):\n",
    "\n",
    "    def lat_lon_to_epsg(lat_max, lon_min):\n",
    "        return str(int(32700 - round((45 + lat_max) / 90, 0) * 100 + round((183 + lon_min) / 6, 0)))\n",
    "\n",
    "    \n",
    "    data = load_config(case_study)\n",
    "\n",
    "       \n",
    "    lats= data['lat']\n",
    "    longs= data['lon']\n",
    "    global EPSG\n",
    "    EPSG = lat_lon_to_epsg(lats[1],longs[0])\n",
    "    \n",
    "    ds = dc.load(product='ls8_level1_usgs', \n",
    "                 measurements = ('red','green','blue','nir','swir1','swir2','quality'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 output_crs='epsg:' + EPSG,\n",
    "                 resolution = (-25,25))\n",
    "\n",
    "    #filter for clouds\n",
    "    clean_pixel_mask = masking.make_mask(\n",
    "    ds.quality,\n",
    "    cloud=False,\n",
    "    radiometric_saturation='none',\n",
    "    terrain_occlusion = False)\n",
    "\n",
    "    masked_cloud = ds.where(clean_pixel_mask)\n",
    "\n",
    "    return masked_cloud\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    \n",
    "    if 'loaded' in locals():\n",
    "        if loaded != config['load_id']:\n",
    "            print ('Retreiving New Cube')\n",
    "            ds = load_into_cube_aws_landsat8()\n",
    "            loaded = config['load_id']\n",
    "\n",
    "    else:\n",
    "        print ('Retreiving Cube')\n",
    "        ds = load_into_cube_aws_landsat8()\n",
    "        loaded = config['load_id']\n",
    "\n",
    "        \n",
    "    target_dataset,desc = BandIndices.calculate_indices(ds,'NDVI')\n",
    "\n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "\n",
    "indicesa = ['NDVI','GNDVI','NDWI', 'NDMI', 'NDBI', 'NBR']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset\n",
    "    target_dataset, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "#EPSG = 3577\n",
    "labels = []\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    plt.figure(0,[10,5])\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    #print (geo_json)\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,int(EPSG))\n",
    "        drill_cube = target_dataset.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "       \n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "        \n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],int(EPSG))\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "        dataMasked = target_dataset.where(mask)\n",
    "        data_masked_mean = dataMasked.mean(dim = ['x','y'])\n",
    "        #data_masked_mean.plot()\n",
    "\n",
    "        time = np.ravel(data_masked_mean.time)\n",
    "        values = np.ravel(data_masked_mean.values)\n",
    "\n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "\n",
    "        xarray.plot.plot(data_masked_mean.interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(values,index = time, columns = [label])],axis = 1)\n",
    "    output_pandas.dropna(thresh=datasetID,inplace=True)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro band_indices_aws_landsat8 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store band_indices_aws_landsat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Landsat 8 AWS WOFS Time series!!!\n",
    "%pylab notebook\n",
    "from importlib import reload  # Python 3.4+ only.\n",
    "import sys\n",
    "import os\n",
    "import osr \n",
    "import ogr\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import rasterio.features\n",
    "import ipywidgets as widgets\n",
    "import xarray\n",
    "from utils import BandIndices\n",
    "\n",
    "#sys.path.append(os.path.expanduser('dea-notebooks/Scripts'))\n",
    "\n",
    "from utils import Water_Classifier\n",
    "Water_Classifier = reload(Water_Classifier)\n",
    "from utils.utils import (transform_from_wgs,\n",
    "    transform_from_wgs_poly)\n",
    "import json\n",
    "from datacube import Datacube\n",
    "from datacube.storage import masking  # Import masking capabilities\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'case_study' not in locals():\n",
    "    global case_study\n",
    "    case_study = './configIndex.txt'\n",
    "\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "\n",
    "global output_pandas\n",
    "output_pandas= pd.DataFrame() \n",
    "\n",
    "global geoJSONs\n",
    "geoJSONs = []\n",
    "\n",
    "global datasetID\n",
    "datasetID = 0\n",
    "\n",
    "###Load EPSG\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "##Define output widget to display table\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "info = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "def load_into_cube_aws_landsat8(measurements = None, cloud_mask = False):\n",
    "\n",
    "    def lat_lon_to_epsg(lat_max, lon_min):\n",
    "        return str(int(32700 - round((45 + lat_max) / 90, 0) * 100 + round((183 + lon_min) / 6, 0)))\n",
    "\n",
    "    \n",
    "    data = load_config(case_study)\n",
    "\n",
    "       \n",
    "    lats= data['lat']\n",
    "    longs= data['lon']\n",
    "    global EPSG\n",
    "    EPSG = lat_lon_to_epsg(lats[1],longs[0])\n",
    "    \n",
    "    ds = dc.load(product='ls8_level1_usgs', \n",
    "                 measurements = ('red','green','blue','nir','swir1','swir2','quality'),\n",
    "                 group_by='solar_day',\n",
    "                 y=tuple(data['lat']),\n",
    "                 x=tuple(data['lon']),\n",
    "                 time=tuple(data['time']),\n",
    "                 output_crs='epsg:' + EPSG,\n",
    "                 resolution = (-25,25))\n",
    "\n",
    "    #filter for clouds\n",
    "    clean_pixel_mask = masking.make_mask(\n",
    "    ds.quality,\n",
    "    cloud=False,\n",
    "    radiometric_saturation='none',\n",
    "    terrain_occlusion = False)\n",
    "    masked_cloud = ds.where(clean_pixel_mask)\n",
    "\n",
    "\n",
    "    return masked_cloud\n",
    "\n",
    "#### Get geometry from config file draw polygon extent.\n",
    "config =load_config(case_study)\n",
    "\n",
    "geoJSON_Extent = config['geoJSON']\n",
    "#m3.add_layer(GeoJSON(data=draw_control2.last_draw))\n",
    "\n",
    "info_last_geom = ogr.CreateGeometryFromJson(str(geoJSON_Extent['geometry']))\n",
    "if info_last_geom:\n",
    "    zoom = 13\n",
    "    center = [info_last_geom.Centroid().GetY(),info_last_geom.Centroid().GetX()]\n",
    "    m3 = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "else:\n",
    "    m3 = Map(center=center, zoom=zoom)\n",
    "    draw_control3 = DrawControl(polygon = {\"shapeOptions\": {\"fillOpacity\": 0}})\n",
    "\n",
    "dc = Datacube()\n",
    "\n",
    "if 'loading' in locals():\n",
    "    ds = None\n",
    "    print ('No Case Study Selected')\n",
    "    target_dataset,desc = None, 'No index selected'\n",
    "else:\n",
    "    geoJSON_Extent['properties']['style']['fillOpacity'] = 0\n",
    "    geoJSON_Extent['properties']['style']['color'] = 'red'\n",
    "    \n",
    "    if 'loaded' in locals():\n",
    "        if loaded != config['load_id']:\n",
    "            print ('Retreiving New Cube')\n",
    "            ds = load_into_cube_aws_landsat8()\n",
    "            loaded = config['load_id']\n",
    "    else:\n",
    "        print ('Retreiving Cube')\n",
    "        ds = load_into_cube_aws_landsat8()\n",
    "        loaded = config['load_id']\n",
    "\n",
    "    \n",
    "    #dse = ds.resample(time='1M').median()\n",
    "    dse = ds.fillna(-9999)\n",
    "    target_dataset,desc = Water_Classifier.water_classifier(dse)\n",
    "    target_dataset = target_dataset * 625\n",
    "\n",
    "    \n",
    "    m3.add_layer(GeoJSON(data=geoJSON_Extent))\n",
    "\n",
    "\n",
    "indicesa = ['WOFS', 'NDWI']\n",
    "\n",
    "with info:\n",
    "         print(desc)\n",
    "\n",
    "indices_buttons = widgets.ToggleButtons(\n",
    "                    options=indicesa,\n",
    "                    description='Product:',\n",
    "                    disabled=False,\n",
    "                    button_style='' \n",
    "                    #tooltips=indices_description,\n",
    "                    )\n",
    "\n",
    "def indices_func(change):\n",
    "    global target_dataset\n",
    "    if indices_buttons.value == 'NDWI':\n",
    "        water_dataset, desc = BandIndices.calculate_indices(ds,indices_buttons.value)\n",
    "\n",
    "        target_dataset_1 = (water_dataset > 0.05).astype(np.float32)\n",
    "\n",
    "        target_dataset = target_dataset_1.to_dataset(name='wofs')\n",
    "        target_dataset = target_dataset * 625\n",
    "    else:\n",
    "          #dse = ds.resample(time='1M').median()\n",
    "        dse = ds.fillna(-9999)\n",
    "        target_dataset,desc = Water_Classifier.water_classifier(dse)\n",
    "        target_dataset = target_dataset * 625\n",
    "\n",
    "    info.clear_output()\n",
    "    with info:\n",
    "        print(desc)\n",
    "\n",
    "indices_buttons.observe(indices_func, names = 'value')\n",
    "\n",
    "\n",
    "dataP = load_config(case_study)\n",
    "\n",
    "#EPSG = int(dataP['output_crs'].split(':')[1])\n",
    "#EPSG = 3577\n",
    "labels = []\n",
    "def plot_nDVI(self, action, geo_json):\n",
    "    global output_pandas\n",
    "    global datasetID\n",
    "\n",
    "    #print (geo_json)\n",
    "    if geo_json['geometry']['type'] == 'Point':\n",
    "\n",
    "        pixel_drill_long,pixel_drill_lat = geo_json['geometry']['coordinates']\n",
    "\n",
    "        pixel_drill_x, pixel_drill_y = transform_from_wgs(pixel_drill_long,pixel_drill_lat,int(EPSG))\n",
    "        drill_cube = target_dataset.sel(x=[pixel_drill_x,pixel_drill_x + 25], y=[pixel_drill_y, pixel_drill_y + 25],\n",
    "                     method = 'nearest')\n",
    "\n",
    "        time = np.ravel(drill_cube.isel(x=[0],y=[0]).time)\n",
    "        values = np.ravel(drill_cube.isel(x=[0],y=[0]).values)\n",
    "\n",
    "        #drill_cube.isel(x=[0],y=[0]).plot()\n",
    "        label = str(indices_buttons.value) + ' point ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "       \n",
    "        xarray.plot.plot(drill_cube.isel(x=[0],y=[0]).interpolate_na(dim = 'time', method = 'nearest'), marker='*')\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=4, mode=\"expand\", labels = labels)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "        datasetID = datasetID + 1\n",
    "        \n",
    "\n",
    "    if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "        geom = transform_from_wgs_poly(geo_json['geometry'],int(EPSG))\n",
    "\n",
    "        mask = rasterio.features.geometry_mask([geom for geoms in [geom]],\n",
    "                                                   out_shape=ds.geobox.shape,\n",
    "                                                   transform=ds.geobox.affine,\n",
    "                                                   all_touched=False,\n",
    "                                                   invert=True)\n",
    "                \n",
    "        dataMasked = target_dataset.where(mask)\n",
    "        #data_masked_max = dataMasked.resample(time='1M').max()\n",
    "        \n",
    "        orig = dse.where(mask)\n",
    "        #orig_max = orig.resample(time='1M').median()\n",
    "        \n",
    "        no_data = orig.red.where(orig.red==-9999).count(dim = ['x','y'])\n",
    "        no_data = no_data * 625\n",
    "                \n",
    "        total_area = mask.sum() * 625\n",
    "                \n",
    "        data_masked = dataMasked.sum(dim = ['x','y'])\n",
    "        \n",
    "        other_masked = total_area - (data_masked + no_data)\n",
    "\n",
    "        label = str(indices_buttons.value) + ' polygon ' + str(datasetID)\n",
    "        labels.append(label)\n",
    "\n",
    "        geo_json['properties']['datasetID'] = datasetID\n",
    "\n",
    "        datasetID = datasetID + 1\n",
    "\n",
    "    geoJSONs.append(geo_json)\n",
    "\n",
    "    plt.figure(num=datasetID, figsize=(10, 3.5))\n",
    "    time_from = np.ravel(data_masked.time)\n",
    "    \n",
    "    plt.ylabel('Area (m^2)')\n",
    "    color_scheme = '#1f77b4','#ff7f0e', '#2ca02c', '#d62728', \n",
    "    plt.set_title = label\n",
    "    #plt.set_yscale('log')\n",
    "    plt.stackplot(time_from,\n",
    "                  data_masked.wofs.values, \n",
    "                  other_masked.wofs.values, \n",
    "                  no_data.values, \n",
    "                  colors = color_scheme,\n",
    "                  labels=['Water','Dry','No Data'])\n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    \n",
    "    output_pandas = pd.concat([output_pandas,pd.DataFrame(data_masked.wofs.values,index = time_from, columns = [label])],axis = 1)\n",
    "    #output_pandas.dropna(thresh=datasetID,inplace=True)\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "         display(output_pandas)\n",
    "\n",
    "draw_control3.on_draw(plot_nDVI)\n",
    "m3.add_control(draw_control3)\n",
    "\n",
    "pixel_drill = widgets.VBox([info,indices_buttons,m3,out])\n",
    "\n",
    "pixel_drill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro water_stackplot_aws_landsat8 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store water_stackplot_aws_landsat8 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
