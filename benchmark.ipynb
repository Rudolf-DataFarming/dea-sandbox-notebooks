{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a series of data cube queries and loads, allowing the user to time various applications in the DEA sandbox. For each test, we aim to provide a reference point, so the user may assess performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the datacube object for future use\n",
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for timing searches and loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `timeit` module that we'll be using to benchmark searches and loads works by calling a predefined functions. Here, we define functions in terms of the key search parameters: `product`, `lat`, `lon` and `time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a seach (without loading) on latitude, longitude and time\n",
    "def find_latlontime(product, lat, lon, time):\n",
    "    return dc.find_datasets(product=product, latitude=lat, longitude=lon, time=time)\n",
    "\n",
    "# Perfom a search (without loading) on latitude and longitude\n",
    "def find_latlon(product, lat, lon):\n",
    "    return dc.find_datasets(product=product, latitude=lat, longitude=lon)\n",
    "\n",
    "# Perfom a search (without loading) on time\n",
    "def find_time(product, time):\n",
    "    return dc.find_datasets(product=product, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fc_percentile_albers_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole colection summary\n",
    "* 28,687 datasets\n",
    "* 9,251,834km$^2$\n",
    "* Annual data product from 1987 to 2017\n",
    "\n",
    "For this search, we define our reference coordinates from [Tile +14, -41](https://dashboard.dea-sandbox.test.frontiersi.io/region/fc_percentile_albers_annual/14_-41)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this benchmark, we time how long it takes to load all of the available data in a given area. We search over all available time. We increase the area for each test by increasing the latitude and longitude bounds by a fixed amount `delta_latlon`. The timing process will take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = 'fc_percentile_albers_annual'\n",
    "\n",
    "ref_lat = -36.0\n",
    "ref_lon = 148.0\n",
    "\n",
    "delta_latlon = 0.5 #amount to scale lat and lon by\n",
    "delta_latlon_list = [i*delta_latlon for i in range(10)]\n",
    "\n",
    "# define dictionary and array to store time taken and amount of data found\n",
    "search_time = {}\n",
    "n_data = []\n",
    "\n",
    "for delta in delta_latlon_list:\n",
    "    print('Timing search for delta =', delta)\n",
    "    lat_search = [ref_lat, ref_lat + delta]\n",
    "    lon_search = [ref_lon, ref_lon + delta]\n",
    "    \n",
    "    search_time[delta] = np.asarray(timeit.repeat('find_latlon(product=product, lat=lat_search, lon=lon_search)',\n",
    "                                                  setup = 'from __main__ import find_latlon, product, lat_search, lon_search',\n",
    "                                                  repeat=7, number=3))/3\n",
    "    n_data.append(len(find_latlon(product=product, lat=lat_search, lon=lon_search)))\n",
    "print('Timing complete!')\n",
    "\n",
    "# calculate the average time taken for each instance\n",
    "average_time = [np.mean(search_time[delta]) for delta in delta_latlon_list]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the current run as the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below allows you to overwrite the default benchmark. We recommend that you save the benchmark to a new file in case you want to keep the existing benchmark as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION TO SAVE MOST RECENT RUN AS THE NEW BENCHMARK\n",
    "# benchmark = {'Number of datasets': n_data,\n",
    "#              'Additional area covered (degrees^2)': np.asarray(delta_latlon_list)**2,\n",
    "#              'Time taken (s)': average_time}\n",
    "\n",
    "# benchmark_df = pd.DataFrame(benchmark,\n",
    "#                             columns = ['Number of datasets',\n",
    "#                                        'Additional area covered (degrees^2)',\n",
    "#                                        'Time taken (s)'])\n",
    "\n",
    "# benchmark_file = 'benchmarks/fc_percentile_albers_annual_search_benchmark.csv'\n",
    "# benchmark_df.to_csv(benchmark_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell plots the amount of time to run the search in terms of the number of datasets found as well as the area the search covers in degrees$^2$. The existing benchmark is also plotted as a reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the existing benchmark\n",
    "existing_benchmark_file = 'benchmarks/fc_percentile_albers_annual_search_benchmark.csv'\n",
    "existing_benchmark = pd.read_csv(existing_benchmark_file, index_col=None)\n",
    "\n",
    "# Plot time vs. number of data sets\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = plt.subplot(111)\n",
    "ax.scatter(existing_benchmark['Number of datasets'], existing_benchmark['Time taken (s)'], label=\"Benchmark\")\n",
    "ax.scatter(n_data, average_time, label='Current time')\n",
    "ax.set_ylabel('Time taken (s)')\n",
    "ax.set_xlabel('Number of datasets')\n",
    "ax.set_title('dc.find_datasets benchmark for fc_percentile_albers_annual')\n",
    "ax.legend()\n",
    "fig.show()\n",
    "\n",
    "# Plot time vs. additional area\n",
    "fig2 = plt.figure(figsize=(5,4))\n",
    "ax2 = plt.subplot(111)\n",
    "ax2.scatter(existing_benchmark['Additional area covered (degrees^2)'], existing_benchmark['Time taken (s)'], label='Benchmark')\n",
    "ax2.scatter(np.asarray(delta_latlon_list)**2, average_time, label='Current time')\n",
    "ax2.set_ylabel('Time taken (s)')\n",
    "ax2.set_xlabel('Area covered (degrees$^2$)')\n",
    "ax2.set_title('dc.find_datasets benchmark for fc_percentile_albers_annual')\n",
    "ax2.legend()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
